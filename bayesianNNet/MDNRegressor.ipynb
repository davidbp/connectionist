{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mixture density networks \n",
    "\n",
    "\n",
    "- About density estimation: http://scikit-learn.org/stable/modules/density.html\n",
    "\n",
    "\n",
    "- http://tullo.ch/articles/speeding-up-isotonic-regression/\n",
    "\n",
    "We want to model the conditional distribution as a mixture of Gaussians, where each Gaussian component parameters are dependent on the input, that is \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "P(y^m \\mid x^m) = \\sum_{k=1}^K \\pi_k(x^m) \\mathcal{N} \\left( y^m \\mid \\mu_k(x^m) , \\sigma_k^2(x^m) \\right)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f8bb30c7320>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREQa2P8H4Ac9Rpw45oUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8bb5615dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate some 1D regression data (reproducing Bishop book data, page 273). \n",
    "# Note that the P(y|x) is not a nice distribution.\n",
    "# E.g. it has three modes for x ~= 0.5\n",
    "N = 200\n",
    "X = np.linspace(0,1,N)\n",
    "Y = X + 0.3 * np.sin(2*3.1415926*X) + np.random.uniform(-0.1, 0.2, N)\n",
    "X,Y = Y,X\n",
    "plt.scatter(X,Y,color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the model\n",
    "\n",
    "Now we will present a mixture density network (MDN) with a single hidden layer. This model can be generalized using as many hidden layers as we want defined just like in a regular multilayer perceptron. The main difference between an standard MLP and a MDN is the output layer which will be specified in the following:\n",
    "\n",
    "#### Weights\n",
    "\n",
    "Let us assume we are training a MDN with $K$ Gaussian components and the objective is to build a density $P(t \\mid x)$ where the target $t$ is a 1D variable (that is we are studying a 1D regression problem).\n",
    "\n",
    "- First layer weights W1 defines a mapping from the input to the hidden layer.\n",
    "\n",
    "- Second layer weights are composed by:\n",
    "\n",
    "    - A weight matrix for the mixing coefficients $\\pi_k$:  ```W_pi``` of shape ```(hidden_size, K)```\n",
    "        \n",
    "    - A weight matrix for the for the means of the Gaussian components $\\mu_k$: ```W_mean``` of shape ```(hidden_size, K)```\n",
    "    \n",
    "    -  A weight matrix for the variances of the Gaussian components $\\sigma_k^2$:  ```W_variance``` of shape ```(hidden_size, K)```\n",
    "\n",
    "- Second layer biases are composed by:\n",
    "\n",
    "    - A bias for the hidden layer: shape (hidden_size,1)\n",
    "    \n",
    "    - A bias for the mixing coefficients: shape (K,1)\n",
    "    \n",
    "    - A bias for the means of the Gaussian components: shape (K,1)\n",
    "    \n",
    "    - A bias for the variances of the Gaussian components: shape (K,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn import utils, base\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils import check_array, check_X_y, column_or_1d\n",
    "from sklearn.utils.extmath import safe_sparse_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function safe_sparse_dot in module sklearn.utils.extmath:\n",
      "\n",
      "safe_sparse_dot(a, b, dense_output=False)\n",
      "    Dot product that handle the sparse matrix case correctly\n",
      "    \n",
      "    Uses BLAS GEMM as replacement for numpy.dot where possible\n",
      "    to avoid unnecessary copies.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(safe_sparse_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.92111535, -0.07208919,  0.46236699,  0.24376157,  0.83892899,\n",
       "       -1.48736362,  0.36939184,  0.25705309,  0.71534711, -0.20409744])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.55907185],\n",
       "       [-0.2859028 ],\n",
       "       [-1.03135695],\n",
       "       [ 1.32765524],\n",
       "       [ 0.97546939]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # softmaxes the columns of x\n",
    "    #z = x - np.max(x, axis=0, keepdims=True) # for safety\n",
    "    e = np.exp(x)\n",
    "    en = e / np.sum(e, axis=0, keepdims=True)\n",
    "    return en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MDNRegressor(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    \"\"\"\n",
    "    Mixture density network regression. This version assumes\n",
    "        - A single layer of hidden units.\n",
    "        - Target variable to be 1-dimensional\n",
    "    \n",
    "    hidden_layer_sizes : tuple, length = n_layers - 2, default (100,)\n",
    " \n",
    "       The ith element represents the number of neurons in the ith\n",
    "       hidden layer.\n",
    "       \n",
    "    activation: {'tanh'}\n",
    "    \n",
    "    shuffle : bool, optional, default True\n",
    "        Whether to shuffle samples in each iteration. \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 hidden_layer_size,\n",
    "                 n_components = 5,\n",
    "                 activation=\"tanh\",\n",
    "                 batch_size= \"auto\",\n",
    "                 shuffle=True):\n",
    "        \n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.n_components = n_components\n",
    "        self.activation = activation\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "            \n",
    "    def _initialize_in_fit(self, \n",
    "                           n_features,\n",
    "                           n_hidden, \n",
    "                           n_outputs, \n",
    "                           n_components):\n",
    "        \"\"\"\n",
    "        Initialize the model weights and biases\n",
    "        \"\"\"\n",
    "        scaling_factor = 0.1\n",
    "        \n",
    "        # n_outputs = y.shape[1]\n",
    "        self.n_outputs_ = n_outputs\n",
    "        self.loss_per_epoch = []\n",
    "        \n",
    "        # Initialize coefficient and intercept layers\n",
    "        self.coefs_ = {'W_1': np.random.randn(n_features, n_hidden) * scaling_factor,\n",
    "                       'W_variance': np.random.randn(n_hidden, n_components) * scaling_factor,\n",
    "                       'W_mean': np.random.randn(n_hidden, n_components) * scaling_factor,\n",
    "                       'W_mix_coeff':np.random.randn(n_hidden, n_components) * scaling_factor}\n",
    "        \n",
    "        self.intercepts_ = {'b_1':  np.zeros(n_hidden, ),\n",
    "                            'b_variance': np.zeros(n_components, ),\n",
    "                            'b_mean': np.zeros(n_components, ),\n",
    "                            'b_mix_coeff':  np.zeros(n_components, )}\n",
    "            \n",
    "    def predict_statistics(self, X):\n",
    "        \"\"\"\n",
    "        For each of the K components predicts\n",
    "            - the expected value (mean of the Gaussian) for a given x\n",
    "            - the variance of the prediction (variance of the Gaussian)\n",
    "            - the weight or coefficient of the component\n",
    "        \"\"\"\n",
    "        # compute hidden activation\n",
    "        \n",
    "        \n",
    "    def _validate_hyperparameters(self):\n",
    "        \"\"\"\n",
    "        Ensures hyperparameters are set correctly\n",
    "        \"\"\"\n",
    "        if not isinstance(self.shuffle, bool):\n",
    "            raise ValueError(\"shuffle must be either True or False, got %s.\" %\n",
    "                             self.shuffle)       \n",
    "    \n",
    "    def _validate_input(self, X, y, incremental):\n",
    "        \n",
    "        if y.ndim == 2 and y.shape[1] == 1:\n",
    "            y = column_or_1d(y, warn=True)\n",
    "        return X,y\n",
    "            \n",
    "    def _forward_pass(self, X):\n",
    "        activations = [X]\n",
    "        \n",
    "\n",
    "    def _compute_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        Returns the probability\n",
    "        \"\"\"\n",
    "             \n",
    "        # Ensure y is 2D\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape((-1, 1))            \n",
    "\n",
    "        ### Forward pass ###\n",
    "        act_h1 = np.tanh( np.dot(X, self.coefs_['W_1']) + self.intercepts_['b_1']  )\n",
    "        \n",
    "        act_means = np.dot(act_h1, self.coefs_['W_mean']) + self.intercepts_['b_mean']\n",
    "        act_variances = np.exp(np.dot(act_h1,self.coefs_['W_variance']) + self.intercepts_['b_variance'])\n",
    "        act_mixing_coeff = softmax(np.dot(act_h1,self.coefs_['W_mix_coeff']) + self.intercepts_['b_mix_coeff'])\n",
    "        \n",
    "        ###\n",
    "        ### Compute Loss (- mean log-likelihood)\n",
    "        ###\n",
    "        n_samples, n_components = act_means.shape\n",
    "        \n",
    "        # prob_per_sample has shape (n_components, n_samples)\n",
    "        prob_per_sample = np.exp(-((y - act_means)**2)/(2*act_variances**2))/(act_variances*np.sqrt(2*np.pi))\n",
    "\n",
    "        pin = act_mixing_coeff * prob_per_sample\n",
    "        # logprob has shape (1,n_samples)\n",
    "        logprob = -np.log(np.sum(pin, axis=0, keepdims=True))\n",
    "        loss = np.sum(logprob)/n_samples\n",
    "        import pdb;pdb.set_trace()\n",
    "        \n",
    "        stats = {}\n",
    "        stats[\"lp\"] = logprob \n",
    "        return stats\n",
    "\n",
    "\n",
    "    def _compute_grads(self, X, y):\n",
    "        \n",
    "        ### Forward pass ###\n",
    "        act_h1 = np.tanh( np.dot(X, self.coefs_['W_1']) + self.intercepts_['b_1']  )\n",
    "        \n",
    "        act_means = np.dot(act_h1, self.coefs_['W_mean']) + self.intercepts_['b_mean']\n",
    "        act_variances = np.exp(np.dot(act_h1,self.coefs_['W_variance']) + self.intercepts_['b_variance'])\n",
    "        act_mixing_coeff = softmax(np.dot(act_h1,self.coefs_['W_mix_coeff']) + self.intercepts_['b_mix_coeff'])\n",
    "        \n",
    "        ###\n",
    "        ### Compute Loss (- mean log-likelihood)\n",
    "        ###\n",
    "        n_samples, n_components = act_means.shape\n",
    "        \n",
    "        # prob_per_sample has shape (n_components, n_samples)\n",
    "        prob_per_sample = np.exp(-((y - act_means)**2)/(2*act_variances**2))/(act_variances*np.sqrt(2*np.pi))\n",
    "        pin = act_mixing_coeff * prob_per_sample\n",
    "        \n",
    "        # logprob has shape (1,n_samples)\n",
    "        logprob = -np.log(np.sum(pin, axis=0, keepdims=True))\n",
    "        loss = np.sum(logprob)/n_samples\n",
    "\n",
    "        ###\n",
    "        ### Gradients \n",
    "        ###\n",
    "        \n",
    "        ### Gradients of the loss with respect to the parameters of the output layer\n",
    "        gammas = pin / np.sum(pin, axis=0, keepdims = True)\n",
    "        dmu = gammas * ((act_means - y)/act_variances**2) / n_samples\n",
    "        dlogsig = gammas * (1.0 - (y - act_means)**2/(act_variances**2)) / n_samples\n",
    "        dpiu = (act_mixing_coeff - gammas) / n_samples\n",
    "    \n",
    "        grads = {}\n",
    "        grads['W_mean'] = np.dot(dmu.T, act_h1).T\n",
    "        grads['W_variance'] = np.dot(dlogsig.T, act_h1).T\n",
    "        grads['W_mix_coeff'] = np.dot(dpiu.T, act_h1).T\n",
    "\n",
    "        grads['b_mean'] = np.sum(dmu, axis=0)\n",
    "        grads['b_variance'] = np.sum(dlogsig, axis=0)\n",
    "        grads['b_mix_coeff'] = np.sum(dpiu, axis=0)\n",
    "\n",
    "        ### Gradients of the loss with respect to the parameters of the first layer\n",
    "        dh = np.dot(self.coefs_['W_mean'], dmu.T) + \\\n",
    "             np.dot(self.coefs_['W_variance'], dlogsig.T) +\\\n",
    "             np.dot(self.coefs_['W_mix_coeff'], dpiu.T)\n",
    "\n",
    "        #import pdb; pdb.set_trace()\n",
    "        \n",
    "        dh = (1.0 - act_h1**2)*dh.T\n",
    "        grads['W_1'] = np.sum(dh, axis=0)       \n",
    "        grads['b_1'] = np.dot(dh.T, X).flatten()\n",
    "        self.loss_per_epoch.append(loss)\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "        \n",
    "    def _fit(self, X, y, n_epochs = 20000, n_epochs_to_print=1000):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \"\"\"\n",
    "        ###########\n",
    "        # Prepare #\n",
    "        ###########\n",
    "        \n",
    "        # Do stuff here\n",
    "        hidden_layer_size = self.hidden_layer_size\n",
    "        \n",
    "        # Validate input parameters.\n",
    "        self._validate_hyperparameters()\n",
    "        if np.any(np.array(hidden_layer_size) <= 0):\n",
    "            raise ValueError(\"hidden_layer_sizes must be > 0, got %s.\" %\n",
    "                             hidden_layer_size)\n",
    "            \n",
    "        # Validate input\n",
    "        X, y = self._validate_input(X, y, incremental=True)\n",
    "        \n",
    "        # Ensure y is 2D\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape((-1, 1))            \n",
    "\n",
    "        self.n_outputs_ = y.shape[1]\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        # Initialize model\n",
    "        self._initialize_in_fit(n_features,\n",
    "                                hidden_layer_size,\n",
    "                                self.n_outputs_,\n",
    "                                self.n_components)\n",
    "        \n",
    "        ###########\n",
    "        # Train   #\n",
    "        ###########\n",
    "        learning_rate = 0.01\n",
    "        \n",
    "        ### Initialize adagrad\n",
    "        mem = {}\n",
    "        for k in self.coefs_.keys(): \n",
    "            mem[k] = np.zeros_like(self.coefs_[k]) \n",
    "        for k in self.intercepts_.keys(): \n",
    "            mem[k] = np.zeros_like(self.intercepts_[k])\n",
    "        \n",
    "        \n",
    "        #nb = n_samples #full batch\n",
    "        #xbatch = np.reshape(X[:nb], (1,nb))\n",
    "        #ybatch = np.reshape(Y[:nb], (1,nb))\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            grads = self._compute_grads(X, y)\n",
    "            if epoch % n_epochs_to_print == 0:\n",
    "                print (\"epoch: \", epoch, \"loss: \", self.loss_per_epoch[-1])\n",
    "\n",
    "            for k,v in grads.items():\n",
    "                mem[k] += grads[k]**2\n",
    "                \n",
    "                if k in self.coefs_:\n",
    "                    self.coefs_[k] += -learning_rate * grads[k] / np.sqrt(mem[k] + 1e-8)\n",
    "                else:\n",
    "                    self.intercepts_[k] += -learning_rate * grads[k] / np.sqrt(mem[k] + 1e-8)                \n",
    "        \n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        return self._fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 1), (200,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(-1,1)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdn =  MDNRegressor(hidden_layer_size=10, n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 loss:  0.0160993764265\n",
      "epoch:  1000 loss:  -0.0228657552289\n",
      "epoch:  2000 loss:  -0.0254963668592\n",
      "epoch:  3000 loss:  -0.0327408437624\n",
      "epoch:  4000 loss:  -0.0310569039853\n",
      "epoch:  5000 loss:  -0.0330759457432\n",
      "epoch:  6000 loss:  -0.03539244037\n",
      "epoch:  7000 loss:  -0.0380374859807\n",
      "epoch:  8000 loss:  -0.0383454857401\n",
      "epoch:  9000 loss:  -0.0350753191918\n",
      "epoch:  10000 loss:  -0.0400612147553\n",
      "epoch:  11000 loss:  -0.0450724908892\n",
      "epoch:  12000 loss:  -0.0368639968515\n",
      "epoch:  13000 loss:  -0.044084565098\n",
      "epoch:  14000 loss:  -0.0411556493412\n",
      "epoch:  15000 loss:  -0.0349220317919\n",
      "epoch:  16000 loss:  -0.0349891216175\n",
      "epoch:  17000 loss:  -0.0413660976969\n",
      "epoch:  18000 loss:  -0.0256860038159\n",
      "epoch:  19000 loss:  -0.0261618928669\n"
     ]
    }
   ],
   "source": [
    "mdn.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 1), (200,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:112: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-24-a35d80926ce1>(116)_compute_loss()\n",
      "-> stats = {}\n",
      "(Pdb) loss\n",
      "inf\n",
      "(Pdb) logprob \n",
      "array([[ inf,  inf,  inf]])\n",
      "(Pdb) pin =\n",
      "*** SyntaxError: invalid syntax\n",
      "(Pdb) pin \n",
      "array([[ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.]])\n",
      "(Pdb) pin.shape\n",
      "(8, 3)\n",
      "(Pdb) act_mixing_coeff.shape\n",
      "(8, 3)\n",
      "(Pdb) act_mixing_coeff\n",
      "array([[ 0.07150622,  0.0677239 ,  0.07628362],\n",
      "       [ 0.14521919,  0.14607263,  0.14399567],\n",
      "       [ 0.10576605,  0.10356144,  0.10836633],\n",
      "       [ 0.21052553,  0.21854085,  0.20088492],\n",
      "       [ 0.17519287,  0.17905113,  0.17037871],\n",
      "       [ 0.08914909,  0.08603195,  0.09296647],\n",
      "       [ 0.06307593,  0.05910529,  0.06816584],\n",
      "       [ 0.13956511,  0.13991282,  0.13895844]])\n",
      "(Pdb) prob_per_sample\n",
      "array([[ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.]])\n",
      "(Pdb) act_means\n",
      "array([[ 0.71118925,  0.7138347 ,  0.69845637],\n",
      "       [ 0.74926073,  0.75009982,  0.73445189],\n",
      "       [ 0.73222756,  0.7338467 ,  0.71830297],\n",
      "       [ 0.76920752,  0.76919463,  0.75345998],\n",
      "       [ 0.75934044,  0.75974047,  0.74404387],\n",
      "       [ 0.72304221,  0.72510114,  0.70962473],\n",
      "       [ 0.70444595,  0.70743434,  0.69211732],\n",
      "       [ 0.74712722,  0.74806142,  0.73242505]])\n",
      "(Pdb) act_variances\n",
      "array([[ 0.00202658,  0.00321517,  0.0019605 ],\n",
      "       [ 0.00155372,  0.0025183 ,  0.00150083],\n",
      "       [ 0.00174986,  0.00280911,  0.00169137],\n",
      "       [ 0.00135176,  0.00221583,  0.00130484],\n",
      "       [ 0.00144816,  0.00236061,  0.00139836],\n",
      "       [ 0.0018657 ,  0.00297967,  0.00180399],\n",
      "       [ 0.00212421,  0.00335738,  0.00205553],\n",
      "       [ 0.00157703,  0.00255301,  0.00152347]])\n",
      "(Pdb) act_mixing_coeff\n",
      "array([[ 0.07150622,  0.0677239 ,  0.07628362],\n",
      "       [ 0.14521919,  0.14607263,  0.14399567],\n",
      "       [ 0.10576605,  0.10356144,  0.10836633],\n",
      "       [ 0.21052553,  0.21854085,  0.20088492],\n",
      "       [ 0.17519287,  0.17905113,  0.17037871],\n",
      "       [ 0.08914909,  0.08603195,  0.09296647],\n",
      "       [ 0.06307593,  0.05910529,  0.06816584],\n",
      "       [ 0.13956511,  0.13991282,  0.13895844]])\n",
      "(Pdb) pin\n",
      "array([[ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.]])\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-f036b0e4464a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmdn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-a35d80926ce1>\u001b[0m in \u001b[0;36m_compute_loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lp\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogprob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-a35d80926ce1>\u001b[0m in \u001b[0;36m_compute_loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lp\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogprob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/david/anaconda/envs/py3/lib/python3.5/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;31m# None\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'line'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'call'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/david/anaconda/envs/py3/lib/python3.5/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mdn._compute_loss(X[0:8],Y[0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "act_h1 = np.tanh( np.dot(X, mdn.coefs_['W_1']) + mdn.intercepts_['b_1']  )\n",
    "\n",
    "act_means = np.dot(act_h1, mdn.coefs_['W_mean']) + mdn.intercepts_['b_mean']\n",
    "act_variances = np.exp(np.dot(act_h1,mdn.coefs_['W_variance']) + mdn.intercepts_['b_variance'])\n",
    "act_mixing_coeff = softmax(np.dot(act_h1,mdn.coefs_['W_mix_coeff']) + mdn.intercepts_['b_mix_coeff'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "###\n",
    "### Compute Loss (- mean log-likelihood)\n",
    "###\n",
    "n_samples, n_components = act_means.shape\n",
    "#import pdb;pdb.set_trace()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (200,) (200,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-33cc57b967bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mact_means\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (200,) (200,3) "
     ]
    }
   ],
   "source": [
    "np.exp(-((Y - act_means)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-ada331f89b0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mact_means\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mact_variances\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mact_variances\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "p.exp(-((Y - act_means)**2)/(2*act_variances**2))/(act_variances*np.sqrt(2*np.pi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# prob_per_sample has shape (n_components, n_samples)\n",
    "prob_per_sample = np.exp(-((y - act_means)**2)/(2*act_variances**2))/(act_variances*np.sqrt(2*np.pi))\n",
    "pin = act_mixing_coeff * prob_per_sample\n",
    "# logprob has shape (1,n_samples)\n",
    "logprob = -np.log(np.sum(pin, axis=0, keepdims=True))\n",
    "loss = np.sum(logprob)/n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# utility function for creating contour plot of the predictions\n",
    "def drawContour(model):\n",
    "    n = 50\n",
    "    xx = np.linspace(0,1,n)\n",
    "    yy = np.linspace(0,1,n)\n",
    "    xm, ym = np.meshgrid(xx, yy)\n",
    "    \n",
    "    X = xm.reshape(xm.size,1)\n",
    "    y =  ym.reshape(ym.size)\n",
    "    \n",
    "    print(\"X :\", X.shape)\n",
    "    print(\"y: \", y.shape)\n",
    "    print(X)\n",
    "    _, _, stats = model._compute_loss(X, y)\n",
    "    logps = stats[\"lp\"]\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(X,Y,color='g')\n",
    "    lp = stats['lp']\n",
    "    plt.contour(xm, ym, np.reshape(logps, (n, n)), levels=np.linspace(lp.min(), lp.max(), 50))\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('3-component Gaussian Mixture Model for P(y|x)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X : (2500, 1)\n",
      "y:  (2500,)\n",
      "[[ 0.        ]\n",
      " [ 0.02040816]\n",
      " [ 0.04081633]\n",
      " ..., \n",
      " [ 0.95918367]\n",
      " [ 0.97959184]\n",
      " [ 1.        ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2500,) (2500,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-be5241ef43c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdrawContour\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmdn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-75-21a226c792fd>\u001b[0m in \u001b[0;36mdrawContour\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mlogps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-9a5d670b0608>\u001b[0m in \u001b[0;36m_compute_loss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mact_means\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;31m# prob_per_sample has shape (n_components, n_samples)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0mprob_per_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mact_means\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mact_variances\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mact_variances\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[0mpin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mact_mixing_coeff\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprob_per_sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;31m# logprob has shape (1,n_samples)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2500,) (2500,3) "
     ]
    }
   ],
   "source": [
    "drawContour(model=mdn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 1), (200,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 1), (200,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.06288342],\n",
       "        [-0.02550665],\n",
       "        [ 0.02676715]]), array([ 0.        ,  0.00502513,  0.01005025]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:3], Y[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdn._initialize_in_fit(n_features=1, n_hidden=4, n_outputs=1, n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xbatch = X[0:3]\n",
    "# activation at the hidden layer for each of the element s in the minibatch\n",
    "act_h1 = np.dot(Xbatch, mdn.coefs_[\"W_1\"]) + mdn.intercepts_[\"b_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.72225560e-03,  -2.82623485e-04,  -1.50002264e-04,\n",
       "          9.53050363e-04,  -4.09432060e-04],\n",
       "       [  6.98577901e-04,  -1.14637177e-04,  -6.08436207e-05,\n",
       "          3.86574398e-04,  -1.66073020e-04],\n",
       "       [ -7.33100586e-04,   1.20302377e-04,   6.38504223e-05,\n",
       "         -4.05678332e-04,   1.74280102e-04]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(act_h1,mdn.coefs_['W_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdn.intercepts_['b_mean'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "act_means = np.dot(act_h1,mdn.coefs_['W_mean']) + mdn.intercepts_['b_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mdn.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-b57f75ee4871>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"b_1\"\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "n_hidden = 10\n",
    "a = {\"b_1\":  np.zeros(n_hidden, 0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-2ce794eaf7f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"b_1\"\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "a = {\"b_1\":  np.zeros(100, 0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-fa0c623da6f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "np.zeros(100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
