{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mixture density networks \n",
    "\n",
    "\n",
    "- About density estimation: http://scikit-learn.org/stable/modules/density.html\n",
    "\n",
    "\n",
    "- http://tullo.ch/articles/speeding-up-isotonic-regression/\n",
    "\n",
    "We want to model the conditional distribution as a mixture of Gaussians, where each Gaussian component parameters are dependent on the input, that is \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "P(y^m \\mid x^m) = \\sum_{k=1}^K \\pi_k(x^m) \\mathcal{N} \\left( y^m \\mid \\mu_k(x^m) , \\sigma_k^2(x^m) \\right)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe704b12490>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIqIAYxAgIgowBgEiogD7/58sSlz0JqNBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe704bf5690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate some 1D regression data (reproducing Bishop book data, page 273). \n",
    "# Note that the P(y|x) is not a nice distribution.\n",
    "# E.g. it has three modes for x ~= 0.5\n",
    "N = 200\n",
    "X = np.linspace(0,1,N)\n",
    "Y = X + 0.3 * np.sin(2*3.1415926*X) + np.random.uniform(-0.1, 0.2, N)\n",
    "X,Y = Y,X\n",
    "plt.scatter(X,Y,color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the model\n",
    "\n",
    "Now we will present a mixture density network (MDN) with a single hidden layer. This model can be generalized using as many hidden layers as we want defined just like in a regular multilayer perceptron. The main difference between an standard MLP and a MDN is the output layer which will be specified in the following:\n",
    "\n",
    "#### Weights\n",
    "\n",
    "Let us assume we are training a MDN with $K$ Gaussian components and the objective is to build a density $P(t \\mid x)$ where the target $t$ is a 1D variable (that is we are studying a 1D regression problem).\n",
    "\n",
    "- First layer weights W1 defines a mapping from the input to the hidden layer.\n",
    "\n",
    "- Second layer weights are composed by:\n",
    "\n",
    "    - A weight matrix for the mixing coefficients $\\pi_k$:  ```W_pi``` of shape ```(hidden_size, K)```\n",
    "        \n",
    "    - A weight matrix for the for the means of the Gaussian components $\\mu_k$: ```W_mean``` of shape ```(hidden_size, K)```\n",
    "    \n",
    "    -  A weight matrix for the variances of the Gaussian components $\\sigma_k^2$:  ```W_variance``` of shape ```(hidden_size, K)```\n",
    "\n",
    "- Second layer biases are composed by:\n",
    "\n",
    "    - A bias for the hidden layer: shape (hidden_size,1)\n",
    "    \n",
    "    - A bias for the mixing coefficients: shape (K,1)\n",
    "    \n",
    "    - A bias for the means of the Gaussian components: shape (K,1)\n",
    "    \n",
    "    - A bias for the variances of the Gaussian components: shape (K,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn import utils, base\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils import check_array, check_X_y, column_or_1d\n",
    "from sklearn.utils.extmath import safe_sparse_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function safe_sparse_dot in module sklearn.utils.extmath:\n",
      "\n",
      "safe_sparse_dot(a, b, dense_output=False)\n",
      "    Dot product that handle the sparse matrix case correctly\n",
      "    \n",
      "    Uses BLAS GEMM as replacement for numpy.dot where possible\n",
      "    to avoid unnecessary copies.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(safe_sparse_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.14390051, -0.17577744,  1.75482121, -0.94836317, -0.69809561,\n",
       "       -0.98091346, -0.89505919,  0.91743192, -0.52511486, -0.04715616])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02456247],\n",
       "       [ 0.66782762],\n",
       "       [ 0.83379884],\n",
       "       [-1.17220891],\n",
       "       [ 1.96622617]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # softmaxes the columns of x\n",
    "    #z = x - np.max(x, axis=0, keepdims=True) # for safety\n",
    "    e = np.exp(x)\n",
    "    en = e / np.sum(e, axis=0, keepdims=True)\n",
    "    return en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MDNRegressor(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    \"\"\"\n",
    "    Mixture density network regression. This version assumes\n",
    "        - A single layer of hidden units.\n",
    "        - Target variable to be 1-dimensional\n",
    "    \n",
    "    hidden_layer_sizes : tuple, length = n_layers - 2, default (100,)\n",
    " \n",
    "       The ith element represents the number of neurons in the ith\n",
    "       hidden layer.\n",
    "       \n",
    "    activation: {'tanh'}\n",
    "    \n",
    "    shuffle : bool, optional, default True\n",
    "        Whether to shuffle samples in each iteration. \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 hidden_layer_size,\n",
    "                 n_components = 5,\n",
    "                 activation=\"tanh\",\n",
    "                 batch_size= \"auto\",\n",
    "                 shuffle=True):\n",
    "        \n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.n_components = n_components\n",
    "        self.activation = activation\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "                \n",
    "            \n",
    "    def _initialize_in_fit(self, n_features, n_hidden, n_outputs, n_components):\n",
    "        \"\"\"\n",
    "        Initialize the model weights and biases\n",
    "        \"\"\"\n",
    "        scaling_factor = 0.1\n",
    "        \n",
    "        # n_outputs = y.shape[1]\n",
    "        self.n_outputs_ = n_outputs\n",
    "        \n",
    "        # Initialize coefficient and intercept layers\n",
    "        self.coefs_ = {'W_1': np.random.randn(n_features, n_hidden) * scaling_factor,\n",
    "                       'W_variance': np.random.randn(n_hidden, n_components) * scaling_factor,\n",
    "                       'W_mean': np.random.randn(n_hidden, n_components) * scaling_factor,\n",
    "                       'W_mix_coeff':np.random.randn(n_hidden, n_components) * scaling_factor}\n",
    "        \n",
    "        self.intercepts_ = {'b_1':  np.zeros(n_hidden, ),\n",
    "                            'b_variance': np.zeros(n_hidden, ),\n",
    "                            'b_mean': np.zeros(n_hidden, ),\n",
    "                            'b_mix_coeff':  np.zeros(n_hidden, )}\n",
    "            \n",
    "    def predict_statistics(self, X):\n",
    "        \"\"\"\n",
    "        For each of the K components predicts\n",
    "            - the expected value (mean of the Gaussian) for a given x\n",
    "            - the variance of the prediction (variance of the Gaussian)\n",
    "            - the weight or coefficient of the component\n",
    "        \"\"\"\n",
    "        # compute hidden activation\n",
    "        \n",
    "        \n",
    "    def _validate_hyperparameters(self):\n",
    "        \"\"\"\n",
    "        Ensures hyperparameters are set correctly\n",
    "        \"\"\"\n",
    "        if not isinstance(self.shuffle, bool):\n",
    "            raise ValueError(\"shuffle must be either True or False, got %s.\" %\n",
    "                             self.shuffle)       \n",
    "    \n",
    "    def _validate_input(self, X, y, incremental):\n",
    "        \n",
    "        if y.ndim == 2 and y.shape[1] == 1:\n",
    "            y = column_or_1d(y, warn=True)\n",
    "        return X,y\n",
    "            \n",
    "    def _forward_pass(self, X):\n",
    "        activations = [X]\n",
    "        \n",
    "\n",
    "    def _compute_loss(self, act_means, act_variances, act_mixing_coeff)\n",
    "        \"\"\"\n",
    "        Returns the probability\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "    def _fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \"\"\"\n",
    "        ###########\n",
    "        # Prepare #\n",
    "        ###########\n",
    "        \n",
    "        # Do stuff here\n",
    "        hidden_layer_size = self.hidden_layer_size\n",
    "        \n",
    "        # Validate input parameters.\n",
    "        self._validate_hyperparameters()\n",
    "        if np.any(np.array(hidden_layer_size) <= 0):\n",
    "            raise ValueError(\"hidden_layer_sizes must be > 0, got %s.\" %\n",
    "                             hidden_layer_size)\n",
    "            \n",
    "        # Validate input\n",
    "        X, y = self._validate_input(X, y, incremental=True)\n",
    "        \n",
    "        # Ensure y is 2D\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape((-1, 1))            \n",
    "\n",
    "        self.n_outputs_ = y.shape[1]\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        # Initialize model\n",
    "        self._initialize_in_fit(n_features,\n",
    "                                hidden_layer_size,\n",
    "                                self.n_outputs_,\n",
    "                                self.n_components)\n",
    "        \n",
    "        ###########\n",
    "        # Train   #\n",
    "        ###########\n",
    "        \n",
    "        ### Forward pass ###\n",
    "        act_h1 = np.tanh( np.dot(X, self.coefs_['W_1']) + self.intercepts_['b_1']  )\n",
    "        \n",
    "        act_means = np.dot(m['W_mean'], act_h1) + m['b_mean']\n",
    "        act_variances = np.exp(np.dot(m['W_variance'], act_h1) + m['b_variance'])\n",
    "        act_mixing_coeff = softmax(np.dot(m['W_mix_coeff'], act_h1) + m['b_mix_coeff'])\n",
    "        \n",
    "        ###\n",
    "        ### Compute Loss (- mean log-likelihood)\n",
    "        ###\n",
    "        n_components, n_samples = act_means.shape\n",
    "        # prob_per_sample has shape (n_components, n_samples)\n",
    "        prob_per_sample = np.exp(-((y - act_means)**2)/(2*act_variances**2))/(act_variances*np.sqrt(2*math.pi))\n",
    "        pin = act_mixing_coeff * prob_per_sample\n",
    "        # logprob has shape (1,n_samples)\n",
    "        logprob = -np.log(np.sum(pin, axis=0, keepdims=True))\n",
    "        loss = np.sum(logprob)/n_samples\n",
    "\n",
    "        ###\n",
    "        ### Gradients of the loss with respect to the parameters of the output layer\n",
    "        ###\n",
    "        gammas = pin / np.sum(pin, axis=0, keepdims = True)\n",
    "        dmu = gammas * ((act_means - y)/sig**2) / n_samples\n",
    "        dlogsig = gammas * (1.0 - (y-act_means)**2/(sig**2)) / n_samples\n",
    "        dpiu = (pi - gammas) / n_samples\n",
    "    \n",
    "        grads = {}\n",
    "        grads['W_mean'] = np.dot(dmu, act_h1.T)\n",
    "        grads['W_variance'] = np.dot(dlogsig, act_h1.T)\n",
    "        grads['W_mix_coeff'] = np.dot(dpiu, act_h.T)\n",
    "\n",
    "        grads['b_mean'] = np.sum(dmu, axis=1, keepdims=True)\n",
    "        grads['b_variance'] = np.sum(dlogsig, axis=1, keepdims=True)\n",
    "        grads['b_mix_coeff'] = np.sum(dpiu, axis=1, keepdims=True)\n",
    "\n",
    "        ### Gradients of the loss with respect to the parameters of the first layer\n",
    "        dh = np.dot(m['Whu'].T, dmu) + np.dot(m['Whs'].T, dlogsig) + np.dot(m['Whp'].T, dpiu)\n",
    "        dh = (1.0-h**2)*dh\n",
    "        grads['W_1'] = np.sum(dh, axis=1, keepdims=True)       \n",
    "        grads['b_1'] = np.dot(dh, x.T)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self._fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MDN =  MDNRegressor(hidden_layer_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 1), (200,))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 1), (200,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-63-f1c590dc7750>(131)_fit()\n",
      "-> return self\n",
      "(Pdb) np.dot(X, self.coefs_[\"W_1\"]).shape\n",
      "(200, 10)\n",
      "(Pdb) np.dot(X, self.coefs_[\"W_1\"]) + self.intercepts_[\"b_1\"]\n",
      "array([[ 0.00339578, -0.00840269, -0.00056861, ..., -0.00355555,\n",
      "         0.00258466, -0.00390758],\n",
      "       [ 0.00238363, -0.00589818, -0.00039913, ..., -0.00249578,\n",
      "         0.00181428, -0.00274289],\n",
      "       [-0.00513246,  0.01270005,  0.00085941, ...,  0.00537395,\n",
      "        -0.00390653,  0.00590603],\n",
      "       ..., \n",
      "       [-0.03598199,  0.08903581,  0.00602502, ...,  0.03767495,\n",
      "        -0.02738735,  0.04140518],\n",
      "       [-0.03541653,  0.0876366 ,  0.00593034, ...,  0.03708289,\n",
      "        -0.02695696,  0.04075449],\n",
      "       [-0.04471425,  0.11064338,  0.0074872 , ...,  0.04681806,\n",
      "        -0.03403382,  0.05145355]])\n",
      "(Pdb) (np.dot(X, self.coefs_[\"W_1\"]) + self.intercepts_[\"b_1\"]).shape\n",
      "(200, 10)\n",
      "(Pdb) np.tanh( np.dot(X, self.coefs_[\"W_1\"]) + self.intercepts_[\"b_1\"]  )\n",
      "array([[ 0.00339576, -0.00840249, -0.00056861, ..., -0.00355553,\n",
      "         0.00258466, -0.00390756],\n",
      "       [ 0.00238362, -0.00589811, -0.00039913, ..., -0.00249577,\n",
      "         0.00181427, -0.00274288],\n",
      "       [-0.00513242,  0.01269937,  0.00085941, ...,  0.0053739 ,\n",
      "        -0.00390651,  0.00590596],\n",
      "       ..., \n",
      "       [-0.03596647,  0.08880128,  0.00602495, ...,  0.03765714,\n",
      "        -0.0273805 ,  0.04138153],\n",
      "       [-0.03540173,  0.08741293,  0.00593027, ...,  0.0370659 ,\n",
      "        -0.02695043,  0.04073194],\n",
      "       [-0.04468447,  0.11019408,  0.00748706, ...,  0.04678388,\n",
      "        -0.03402069,  0.0514082 ]])\n",
      "(Pdb) np.tanh( np.dot(X, self.coefs_[\"W_1\"]) + self.intercepts_[\"b_1\"]  ).shape\n",
      "(200, 10)\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-551ba265df0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMDN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-63-f1c590dc7750>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-63-f1c590dc7750>\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-f1c590dc7750>\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/david/anaconda/envs/py3/lib/python3.5/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;31m# None\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'line'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'call'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/david/anaconda/envs/py3/lib/python3.5/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MDN.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-84c2bdcf294c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"b_1\"\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "n_hidden = 10\n",
    "a = {\"b_1\":  np.zeros(n_hidden, 0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-2ce794eaf7f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"b_1\"\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "a = {\"b_1\":  np.zeros(100, 0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-fa0c623da6f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "np.zeros(100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
