{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Diary for CRBM implementation\n",
    "\n",
    "\n",
    "\n",
    "This notebook shows the parts from `crbm.py` with some details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import numexpr as ne\n",
    "import sklearn\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### read data from  `../Datasets/motion.mat`\n",
    "\n",
    "More data from human motion captures can be found here:\n",
    "\n",
    "http://people.csail.mit.edu/ehsu/work/sig05stf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat  # this is the SciPy module that loads mat-files\n",
    "data = loadmat('../Datasets/motion.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'skel', 'Motion'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = data[\"Motion\"][0][0]\n",
    "X2 = data[\"Motion\"][0][1]\n",
    "X3 = data[\"Motion\"][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1750, 108), (1040, 108), (1040, 108))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape, X2.shape, X2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several features are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(X1 - np.min(X1,0)) / (np.max(X1,0) - np.min(X1,0))* (np.min(X1,0) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1049.559326171875, 490.09881591796881, (1750, 108))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[:,3].min(), X1[:,3].max(), X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = X1.shape[1]\n",
    "for f in range(n_features):\n",
    "    max_val, min_val =  X1[:, f].max(), X1[:, f].min()\n",
    "    if (max_val - min_val) != 0:\n",
    "        X1[:, f] = ( X1[:, f]  - min_val)  / (max_val - min_val)\n",
    "    else:\n",
    "        #print(f, max_val, max_val)\n",
    "        X1[:, f] = ( X1[:, f]  - min_val) # / (max_val - min_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.min(), X1.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRBM class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 10\n",
    "b=2\n",
    "np.zeros([a,b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on the weight initialization\n",
    "\n",
    "A relevant aspect of learning algorithms is the initial magnitude of the weights. It turns out that the magnitude of the weights in a layer can impact the net input of the layer above and this can lead to unnexpected error. In the case of the RBM the Bernoulli hidden units generate samples acording to a logistic. Since the logistic contains an exponential this can lead to numerical problems if the numbers in the exponential are big.\n",
    "\n",
    "#### Scaling using a fixed min-max interval\n",
    "\n",
    "In order to facilitate introducing the problem we can start with a concrete example and generalize from there. Let us assume we have 500 visible units and 100 visible units. Let us consider a visible vector with values between \n",
    "0 and 1. Then the net input of hidden unit $i$ will be\n",
    "\n",
    "$$\n",
    "z_i = {\\boldsymbol W_i} \\cdot {\\boldsymbol  x} + b_i\n",
    "$$\n",
    "\n",
    "If we  initialize ${\\boldsymbol W_i} $ to have values in $[-0.5, 0.5]$  and $b_i=0$ then \n",
    "\n",
    "$$\n",
    "{\\boldsymbol W_i} \\cdot {\\boldsymbol  x}  \\leq 0.5 * 1 + \\dots 0.5 * 1 = 500*0.5 = 250\n",
    "$$\n",
    "\n",
    "In the worst case scenario when computing the sigmoid of that value we will have:\n",
    "\n",
    "$$\n",
    "   a_i = \\frac{1}{1 + \\text{e}^{-250}}\n",
    "$$\n",
    "\n",
    "We can easily run into numerical problems for the exponential of a number with \"big magnitude\".\n",
    "\n",
    "#### Scaling taking into acount the number of units in the layers\n",
    "\n",
    "Let us consider the same example as above but where we scale the weights by the maximum of the number of hidden units and visible units. In this case 500. Now all of a sudden\n",
    "\n",
    "$$\n",
    "{\\boldsymbol W_i} \\cdot {\\boldsymbol  x}  \\leq \\frac{0.5}{500}  1 + \\dots \\frac{0.5}{500}  1 = 500 \\cdot \\frac{0.5}{500} = 0.5\n",
    "$$\n",
    "\n",
    "What whould happen now if we conside that we have an input layer with 100000 units? Well the maximum net input of the initial weights is ensured to be equal to the maximum value achievable in the input feature space.\n",
    "\n",
    "$$\n",
    "{\\boldsymbol W_i} \\cdot {\\boldsymbol  x}  \\leq \\frac{0.5}{100000 }  1 + \\dots \\frac{0.5}{100000 }  1 = 100000  \\cdot \\frac{0.5}{100000} = 0.5\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CRBM:\n",
    "    def __init__(self, n_vis, n_hid, n_cond, seed=42, sigma=0.2, monitor_time=True):\n",
    "\n",
    "        self.previous_xneg = None\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        scale_factor = n_vis * n_cond\n",
    "        \n",
    "        W = (1./scale_factor) * np.random.normal(0, sigma, [n_hid, n_vis])   # vis to hid\n",
    "        A = (1./scale_factor) * np.random.normal(0, sigma, [n_vis, n_vis * n_cond])  # cond to vis\n",
    "        B = (1./scale_factor) * np.random.normal(0, sigma, [n_hid, n_vis * n_cond])  # cond to hid\n",
    "\n",
    "        v_bias = np.zeros([n_vis, 1]) \n",
    "        h_bias = np.zeros([n_hid, 1])\n",
    "\n",
    "        dy_v_bias = np.zeros([n_vis, 1])\n",
    "        dy_h_bias = np.zeros([n_hid, 1])\n",
    "\n",
    "        self.W = np.array(W, dtype='float32')\n",
    "        self.A = np.array(A, dtype='float32')\n",
    "        self.B = np.array(B, dtype='float32')\n",
    "        self.v_bias = v_bias\n",
    "        self.h_bias = h_bias\n",
    "        self.dy_v_bias = dy_v_bias\n",
    "        self.dy_h_bias = dy_h_bias\n",
    "        \n",
    "        self.n_vis = n_vis\n",
    "        self.n_hid = n_hid\n",
    "        self.n_his = n_cond\n",
    "        \n",
    "        self.num_epochs_trained = 0\n",
    "        self.lr = 0\n",
    "        self.monitor_time = monitor_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crbm = CRBM(n_vis=108, n_hid=256, n_cond=20, seed=123, sigma = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256, 108), (108, 2160), (256, 2160))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crbm.W.shape, crbm.A.shape, crbm.B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sig(v):\n",
    "    return ne.evaluate(\"1/(1 + exp(-v))\")\n",
    "\n",
    "def split_vis(crbm: CRBM, vis: np.ndarray):\n",
    "    n_his = vis.shape[0]\n",
    "    cond = vis[0:(n_his-1), :].T\n",
    "    x = vis[[n_his-1],:].T\n",
    "    \n",
    "    assert  crbm.n_vis == x.shape[0] and crbm.n_vis == cond.shape[0], \\\n",
    "            \"crbm.n_vis = {}, is different from x.shape[0] = {} or cond.shape[0] = {}\".format(crbm.n_vis,\n",
    "                                                                                                  x.shape[0],\n",
    "                                                                                                  cond.shape[0])\n",
    "    return x, cond\n",
    "\n",
    "\n",
    "def dynamic_biases_up(crbm: CRBM, cond: np.ndarray):\n",
    "    crbm.dy_v_bias = np.dot(crbm.A, cond) + crbm.v_bias \n",
    "    crbm.dy_h_bias = np.dot(crbm.B, cond) + crbm.h_bias\n",
    "        \n",
    "        \n",
    "def hid_means(crbm: CRBM, vis: np.ndarray):\n",
    "    p = np.dot(crbm.W, vis) + crbm.dy_h_bias\n",
    "    return sig(p)\n",
    "    \n",
    "    \n",
    "def vis_means(crbm: CRBM, hid: np.ndarray):   \n",
    "    p = np.dot(crbm.W.T, hid) + crbm.dy_v_bias\n",
    "    return sig(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, 108), 20)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X1[0:21, :]\n",
    "X.shape, crbm.n_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108, 1), (108, 20))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis, cond = split_vis(crbm, X)\n",
    "vis.shape, cond.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute gradients\n",
    "\n",
    "```\n",
    "function gibbs(rbm::AbstractRBM, vis::Mat; n_times=1)\n",
    "    v_pos = vis\n",
    "    h_pos = sample_hiddens(rbm, v_pos)\n",
    "    v_neg = sample_visibles(rbm, h_pos)\n",
    "    h_neg = sample_hiddens(rbm, v_neg)\n",
    "    for i=1:n_times-1\n",
    "        v_neg = sample_visibles(rbm, h_neg)\n",
    "        h_neg = sample_hiddens(rbm, v_neg)\n",
    "    end\n",
    "    return v_pos, h_pos, v_neg, h_neg\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample_hiddens(crbm: CRBM, v: np.ndarray, cond: np.ndarray):\n",
    "    h_mean = sig( np.dot(crbm.W, v) +  np.dot(crbm.B, cond) + crbm.h_bias)\n",
    "    h_sample = h_mean > np.random.random(h_mean.shape).astype(np.float32)\n",
    "    return h_sample, h_mean\n",
    "\n",
    "\n",
    "def sample_visibles(crbm: CRBM, h: np.ndarray, cond: np.ndarray):\n",
    "    \"\"\"\n",
    "    Notice we don't sample or put the sigmoid here since visible units are Gaussian\n",
    "    \"\"\"\n",
    "    v_mean = np.dot(crbm.W.T, h) + np.dot(crbm.A, cond) + crbm.v_bias  \n",
    "    return v_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CDK(crbm, vis,cond, K=1):\n",
    "    v_pos_mean = vis\n",
    "    h_pos_sample, h_pos_mean    = sample_hiddens(crbm,  v_pos_mean, cond)\n",
    "    v_neg_mean                  = sample_visibles(crbm, h_pos_mean, cond)\n",
    "    h_neg_sample, h_neg_mean    = sample_hiddens(crbm,  v_neg_mean, cond)\n",
    "\n",
    "    for i in range(K-1):\n",
    "        v_neg_mean           = sample_visibles(crbm, h_neg_mean, cond)\n",
    "        h_neg, h_neg_mean    = sample_hiddens(crbm,  v_neg_mean, cond)\n",
    "    \n",
    "    return v_pos_mean, h_pos_mean , v_neg_mean, h_neg_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update history in matrix form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 1],\n",
       "       [3, 2, 1],\n",
       "       [3, 2, 1]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[3,3,3],[2,2,2],[1,1,1]]).T\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,0:-1] = a[:,1:]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 7],\n",
       "       [2, 1, 7],\n",
       "       [2, 1, 7]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,-1] = [7,7,7]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_history_as_mat(current_hist, vec_to_hist):\n",
    "    current_hist[:,0:-1] = current_hist[:,1:]\n",
    "    current_hist[:,-1] = vec_to_hist\n",
    "    return current_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 7],\n",
       "       [2, 1, 7],\n",
       "       [2, 1, 7]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[3,3,3],[2,2,2],[1,1,1]]).T\n",
    "v = np.array([7,7,7])\n",
    "update_history_as_mat(a, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update history in column vector form\n",
    "\n",
    "Notice that first column in the matrix corresponds to oldest feature vector (first to be popped out):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 1],\n",
       "       [3, 2, 1],\n",
       "       [3, 2, 1]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[3,3,3],[2,2,2],[1,1,1]]).T\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what we want to do\n",
    "a = np.array([a.flatten('F')]).T\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7],\n",
       "       [7],\n",
       "       [7]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_new = np.array([[7,7,7]]).T\n",
    "n_feat = v_new.shape[0]\n",
    "v_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0:-n_feat] = a[n_feat:] \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-3:] = v_new\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_history_as_vec(current_hist_vec, v_new):\n",
    "    n_feat = v_new.shape[0]\n",
    "    current_hist_vec[0:-n_feat] = current_hist_vec[n_feat:] \n",
    "    current_hist_vec[-n_feat:] = v_new\n",
    "    return current_hist_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[3,3,3],[2,2,2],[1,1,1]]).T\n",
    "a = np.array([a.flatten('F')]).T\n",
    "\n",
    "update_history_as_vec(a, v_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def history_mat_to_vec(cond):\n",
    "    return np.array([cond.flatten('F')]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient(crbm, X):\n",
    "    \"\"\"\n",
    "    Computes an approximated gradient of the likelihod (for a given minibatch X) with\n",
    "    respect to the parameters. \n",
    "    \"\"\"\n",
    "    vis, cond = split_vis(crbm, X)\n",
    "    cond = history_mat_to_vec(cond)\n",
    "        \n",
    "    v_pos, h_pos, v_neg, h_neg = CDK(crbm, vis, cond)\n",
    "    n_obs = vis.shape[1]\n",
    "    \n",
    "    # for a sigle observation:  dW = h * v^T - h_hat * v_hat^T\n",
    "    dW = ( np.dot(h_pos, v_pos.T) - np.dot(h_neg, v_neg.T) ) * (1./n_obs)\n",
    "    dA = ( np.dot(v_pos, cond.T)  - np.dot(v_neg, cond.T)  ) * (1./n_obs)\n",
    "    dB = ( np.dot(h_pos, cond.T)  - np.dot(h_neg, cond.T)  ) * (1./n_obs) \n",
    "    \n",
    "    dv_bias = np.mean(v_pos - v_neg, axis=1, keepdims=True)\n",
    "    dh_bias = np.mean(h_pos - h_neg, axis=1, keepdims=True)\n",
    "    #print(\"n_obs:\", n_obs)\n",
    "    \n",
    "    rec_error = np.linalg.norm(v_pos - v_neg)\n",
    "    #print( np.sqrt(np.sum((v_pos - v_neg)**2)))\n",
    "    \n",
    "    return dW, dA, dB, dv_bias, dh_bias, rec_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X1[0:21,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, 108), 20)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, crbm.n_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notice that the history is converted to a \"long column vector\" concatenating\n",
    "# all the rows of the n_his vectors into a single vector of `n_vis * n_his` elements.\n",
    "# This is done by `cond = np.array([cond.flatten()]).T`\n",
    "\n",
    "dW, dA, dB, dv_bias, dh_bias, rec_error = compute_gradient(crbm, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, 108), 0.04049332114225114)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, rec_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD  example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights_sgd(crbm, grads, learning_rate):\n",
    "    \n",
    "    dW, dA, dB, dv_bias, dh_bias = grads #rec_error = compute_gradient(crbm, X)\n",
    "    crbm.W += dW * learning_rate\n",
    "    crbm.A += dA * learning_rate\n",
    "    crbm.B += dB * learning_rate\n",
    "    \n",
    "    crbm.v_bias += dv_bias * learning_rate\n",
    "    crbm.h_bias += dh_bias * learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error: 3.78337594862\n",
      "reconstruction error: 2.41012258836\n",
      "reconstruction error: 1.53358720715\n",
      "reconstruction error: 0.974943280007\n",
      "reconstruction error: 0.619385008974\n",
      "reconstruction error: 0.393317339107\n",
      "reconstruction error: 0.24968532226\n",
      "reconstruction error: 0.158473379117\n",
      "reconstruction error: 0.100568883797\n",
      "reconstruction error: 0.063816797377\n"
     ]
    }
   ],
   "source": [
    "crbm = CRBM(n_vis=108, n_hid=256, n_cond=20, seed=123, sigma = 0.3)\n",
    "learning_rate = 0.001\n",
    "\n",
    "for i in range(10):\n",
    "    dW, dA, dB, dv_bias, dh_bias, err = compute_gradient(crbm, X)\n",
    "    grads  = (dW, dA, dB, dv_bias, dh_bias)\n",
    "    update_weights_sgd(crbm, grads,  learning_rate)\n",
    "    print(\"reconstruction error:\", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, 108), 20)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, crbm.n_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 108)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights_sgd_momentum(crbm, grads, learning_rate, ctx, momentum=0.9):\n",
    "    \n",
    "    dW, dA, dB, dv_bias, dh_bias = grads \n",
    "    \n",
    "    ctx[\"W_vel\"]        = ctx[\"W_vel\"]      * momentum    +  dW      * learning_rate\n",
    "    ctx[\"A_vel\"]        = ctx[\"A_vel\"]      * momentum    +  dA      * learning_rate\n",
    "    ctx[\"B_vel\"]        = ctx[\"B_vel\"]      * momentum    +  dB      * learning_rate\n",
    "    ctx[\"v_bias_vel\"]   = ctx[\"v_bias_vel\"] * momentum    +  dv_bias * learning_rate\n",
    "    ctx[\"h_bias_vel\"]   = ctx[\"h_bias_vel\"] * momentum    +  dh_bias * learning_rate\n",
    "    \n",
    "    crbm.W += ctx[\"W_vel\"]\n",
    "    crbm.A += ctx[\"A_vel\"] \n",
    "    crbm.B += ctx[\"B_vel\"] \n",
    "    \n",
    "    crbm.v_bias += ctx[\"v_bias_vel\"]\n",
    "    crbm.h_bias += ctx[\"h_bias_vel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error: 3.78337594862\n",
      "reconstruction error: 2.41012258836\n",
      "reconstruction error: 1.25849845438\n",
      "reconstruction error: 0.56923316708\n",
      "reconstruction error: 0.223516062067\n",
      "reconstruction error: 0.0726995199743\n",
      "reconstruction error: 0.0159650091587\n",
      "reconstruction error: 0.00121751691281\n",
      "reconstruction error: 0.00420901999359\n",
      "reconstruction error: 0.00326888605879\n"
     ]
    }
   ],
   "source": [
    "crbm = CRBM(n_vis=108, n_hid=256, n_cond=20, seed=123, sigma = 0.3)\n",
    "learning_rate = 0.001\n",
    "\n",
    "ctx = { \"W_vel\" : np.zeros(crbm.W.shape), \n",
    "        \"A_vel\" : np.zeros(crbm.A.shape),\n",
    "        \"B_vel\" : np.zeros(crbm.B.shape), \n",
    "        \"v_bias_vel\" : np.zeros(crbm.v_bias.shape), \n",
    "        \"h_bias_vel\" : np.zeros(crbm.h_bias.shape)}\n",
    "\n",
    "for i in range(10):\n",
    "    dW, dA, dB, dv_bias, dh_bias, err = compute_gradient(crbm, X)\n",
    "    grads  = (dW, dA, dB, dv_bias, dh_bias)\n",
    "    update_weights_sgd_momentum(crbm, grads, learning_rate, ctx, momentum=0.2)\n",
    "    print(\"reconstruction error:\", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get slice of data\n",
    "\n",
    "Given a timeseries where column `k` corresponds to a feature vector for the measurements of the timeseries at time `k`, we would like to take a slice of `n_his` values to feed the CRBM with a visible vector and a history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 108)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_slice_at_position_k(X, k, n_his):\n",
    "    \"\"\"\n",
    "    Returns a slice of shape  `(n_his + 1)` with the last column beeing the visible\n",
    "    vector at the current time step `k`.\n",
    "    \"\"\"\n",
    "    assert k > n_his, \"Position k = {} is lower than n_his = {}\".format(k, n_his)\n",
    "    assert k <= X.shape[1], \"Position k = {} is bigger than number of timesteps of X.shape[1] = {}\".format(k, X.shape[0])\n",
    "    return X[:, (k-(n_his+1)):k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr shape:  (108, 1750) \n",
      "slice shape: (108, 21)\n"
     ]
    }
   ],
   "source": [
    "X_tr = X1.T\n",
    "print(\"X_tr shape: \", X_tr.shape, \"\\nslice shape:\", get_slice_at_position_k(X_tr, 520, crbm.n_his).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train some  epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108, 1750), 1750, 108, 256, 20)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr = X1.T\n",
    "X_tr.shape, X_tr.shape[1],  crbm.n_vis, crbm.n_hid, crbm.n_his"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With momentum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec error:  0.217831253038\n",
      "rec error:  0.205777576279\n",
      "rec error:  0.200893142104\n",
      "rec error:  0.192539693971\n",
      "rec error:  0.190128312883\n",
      "rec error:  0.184177126557\n",
      "rec error:  0.181172568991\n",
      "rec error:  0.177286164251\n",
      "rec error:  0.175127015776\n",
      "rec error:  0.171605778243\n",
      "CPU times: user 8min 46s, sys: 20.6 s, total: 9min 7s\n",
      "Wall time: 4min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crbm = CRBM(n_vis=108, n_hid=256, n_cond=20, seed=123, sigma = 0.3)\n",
    "n_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "ctx = { \"W_vel\" : np.zeros(crbm.W.shape), \n",
    "        \"A_vel\" : np.zeros(crbm.A.shape),\n",
    "        \"B_vel\" : np.zeros(crbm.B.shape), \n",
    "        \"v_bias_vel\" : np.zeros(crbm.v_bias.shape), \n",
    "        \"h_bias_vel\" : np.zeros(crbm.h_bias.shape)}\n",
    "\n",
    "for n in range(n_epochs):\n",
    "    err_epoch = 0\n",
    "    iters = 0\n",
    "    for k in range(crbm.n_his + 1, X_tr.shape[1] ):\n",
    "\n",
    "        X_curr = get_slice_at_position_k(X_tr, k, crbm.n_his)\n",
    "        dW, dA, dB, dv_bias, dh_bias, rec_error = compute_gradient(crbm, X_curr.T)\n",
    "        grads = (dW, dA, dB, dv_bias, dh_bias)\n",
    "        update_weights_sgd_momentum(crbm, grads, learning_rate, ctx, momentum=0.2)\n",
    "        iters +=1\n",
    "        err_epoch += rec_error\n",
    "        \n",
    "    print(\"rec error: \", err_epoch/iters)#, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec error:  0.177934999331\n",
      "rec error:  0.141553903892\n",
      "rec error:  0.131299616937\n",
      "rec error:  0.125575453928\n",
      "rec error:  0.122641461558\n",
      "rec error:  0.120646690804\n",
      "rec error:  0.118690350513\n",
      "rec error:  0.117463262574\n",
      "rec error:  0.117166993136\n",
      "rec error:  0.116768897521\n",
      "CPU times: user 4min 38s, sys: 10.5 s, total: 4min 48s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crbm = CRBM(n_vis=108, n_hid=256, n_cond=20, seed=123, sigma = 0.3)\n",
    "n_epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "ctx = { \"W_vel\" : np.zeros(crbm.W.shape), \n",
    "        \"A_vel\" : np.zeros(crbm.A.shape),\n",
    "        \"B_vel\" : np.zeros(crbm.B.shape), \n",
    "        \"v_bias_vel\" : np.zeros(crbm.v_bias.shape), \n",
    "        \"h_bias_vel\" : np.zeros(crbm.h_bias.shape)}\n",
    "\n",
    "for n in range(n_epochs):\n",
    "    err_epoch = 0\n",
    "    iters = 0\n",
    "    for k in range(crbm.n_his + 1, X_tr.shape[1] ):\n",
    "\n",
    "        X_curr = get_slice_at_position_k(X_tr, k, crbm.n_his)\n",
    "        dW, dA, dB, dv_bias, dh_bias, rec_error = compute_gradient(crbm, X_curr.T)\n",
    "        grads = (dW, dA, dB, dv_bias, dh_bias)\n",
    "        update_weights_sgd_momentum(crbm, grads, learning_rate, ctx, momentum=0.2)\n",
    "        iters +=1\n",
    "        err_epoch += rec_error\n",
    "        \n",
    "    print(\"rec error: \", err_epoch/iters)#, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without momentum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec error:  0.261291221323\n",
      "rec error:  0.165687439572\n",
      "rec error:  0.157796974577\n",
      "rec error:  0.151697051663\n",
      "rec error:  0.147223542096\n",
      "rec error:  0.142775353286\n",
      "rec error:  0.139548651882\n",
      "rec error:  0.137773346896\n",
      "rec error:  0.135261046111\n",
      "rec error:  0.134184415863\n",
      "CPU times: user 3min 51s, sys: 7.56 s, total: 3min 59s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crbm = CRBM(n_vis=108, n_hid=256, n_cond=11, seed=123, sigma = 0.3)\n",
    "n_epochs = 10\n",
    "learning_rate = 0.01 # we have increased the  learning rate\n",
    "\n",
    "for n in range(n_epochs):\n",
    "    err_epoch = 0\n",
    "    iters = 0\n",
    "    for k in range(crbm.n_his + 1, X_tr.shape[1] ):\n",
    "\n",
    "        X_curr = get_slice_at_position_k(X_tr, k, crbm.n_his)\n",
    "        dW, dA, dB, dv_bias, dh_bias, rec_error = compute_gradient(crbm, X_curr.T)\n",
    "        grads = (dW, dA, dB, dv_bias, dh_bias)\n",
    "        update_weights_sgd(crbm, grads,  learning_rate)\n",
    "        iters +=1\n",
    "        err_epoch += rec_error\n",
    "        \n",
    "    print(\"rec error: \", err_epoch/iters)#, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec error:  16.0121818101\n",
      "rec error:  69.9333785553\n",
      "rec error:  270.592464332\n",
      "rec error:  1116.66368732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in add\n",
      "  after removing the cwd from sys.path.\n",
      "/home/david/anaconda/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in add\n",
      "  \"\"\"\n",
      "/home/david/anaconda/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in greater\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec error:  nan\n",
      "rec error:  nan\n",
      "rec error:  nan\n",
      "rec error:  nan\n",
      "rec error:  nan\n",
      "rec error:  nan\n",
      "CPU times: user 4min 6s, sys: 7.82 s, total: 4min 14s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crbm = CRBM(n_vis=108, n_hid=256, n_cond=12, seed=123, sigma = 0.3)\n",
    "n_epochs = 10\n",
    "learning_rate = 0.01 # we have increased the  learning rate\n",
    "\n",
    "for n in range(n_epochs):\n",
    "    err_epoch = 0\n",
    "    iters = 0\n",
    "    for k in range(crbm.n_his + 1, X_tr.shape[1] ):\n",
    "\n",
    "        X_curr = get_slice_at_position_k(X_tr, k, crbm.n_his)\n",
    "        dW, dA, dB, dv_bias, dh_bias, rec_error = compute_gradient(crbm, X_curr.T)\n",
    "        grads = (dW, dA, dB, dv_bias, dh_bias)\n",
    "        update_weights_sgd(crbm, grads,  learning_rate)\n",
    "        iters +=1\n",
    "        err_epoch += rec_error\n",
    "        \n",
    "    print(\"rec error: \", err_epoch/iters)#, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crbm = CRBM(n_vis=108, n_hid=256, n_cond=12, seed=123, sigma = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crbm.n_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 1296)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crbm.A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.02787968"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crbm.A[:,5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 12)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_curr[:,:-1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108, 1750), (108,))"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a timeseries where rows are features and columns timesteps (1750 timesteps and 108 features)\n",
    "X_tr.shape, X_tr[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(crbm, vis, cond_as_vec, n_gibbs=10):\n",
    "    \"\"\" \n",
    "    Given initialization(s) of visibles and matching history, generate a sample in the future.\n",
    "    \n",
    "        vis:  n_vis * 1 array\n",
    "            \n",
    "        cond_as_vec: n_hist * n_vis array\n",
    "            \n",
    "        n_gibbs : int\n",
    "            number of alternating Gibbs steps per iteration\n",
    "    \"\"\"\n",
    "    \n",
    "    assert cond_as_vec.shape[1] ==1, \"cond_as_vec has to be a column vector\"\n",
    "    \n",
    "    n_seq = vis.shape[0]\n",
    "    #import pdb; pdb.set_trace()\n",
    "    v_pos, h_pos, v_neg, h_neg = CDK(crbm, vis, cond_as_vec, n_gibbs)\n",
    "    \n",
    "    return v_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_n_samples(crbm, vis, cond_as_vec, n_samples, n_gibbs=10):\n",
    "    \"\"\" \n",
    "    Given initialization(s) of visibles and matching history, generate a n_samples in the future.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert cond_as_vec.shape[1] ==1, \"cond_as_vec has to be a column vector\"\n",
    "    \n",
    "    samples = []\n",
    "    for i in range(n_samples):\n",
    "        v_new = generate(crbm, vis, cond_as_vec, n_gibbs)\n",
    "        \n",
    "        # This should not be here\n",
    "        #v_new = v_new/np.linalg.norm(v_new)      \n",
    "        update_history_as_vec(cond_as_vec, v_new)\n",
    "        \n",
    "        samples.append(v_new)\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v    = X_tr[:, [crbm.n_his+1]]\n",
    "hist = X_tr[:, 0:crbm.n_his+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-134e3602d608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcrbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_vis\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "crbm.n_vis,  v.shape, hist.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-5992fc62b937>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_vis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "vis, cond = split_vis(crbm, hist.T)\n",
    "\n",
    "cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cond_as_vec =  history_mat_to_vec(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.94352132901966146, 0.0)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_as_vec.max(), cond_as_vec.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108, 1), (1080, 1), 108)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape, cond_as_vec.shape, crbm.n_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_as_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108, 1080), (256, 1080), (256, 108))"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crbm.A.shape, crbm.B.shape, crbm.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = generate_n_samples(crbm, v, cond_as_vec, n_samples = 100, n_gibbs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.28260305981799355"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_as_vec.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-c12b76fc8b93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'samples' is not defined"
     ]
    }
   ],
   "source": [
    "len(samples), len(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.315945265203 -0.0131379444896\n",
      "0.314247687258 -0.016026380618\n",
      "0.326866965915 -0.0191752262314\n",
      "0.343980369273 -0.0219303673418\n",
      "0.368368530509 -0.0277843109218\n",
      "0.0294414211905 -0.277440092798\n"
     ]
    }
   ],
   "source": [
    "print(samples[0].max(), samples[0].min())\n",
    "print(samples[1].max(), samples[1].min())\n",
    "print(samples[2].max(), samples[2].min())\n",
    "print(samples[3].max(), samples[3].min())\n",
    "print(samples[4].max(), samples[4].min())\n",
    "print(samples[-1].max(), samples[-1].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X = X1[0:21,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = X1[21:121,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = np.array(samples).reshape(100,108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 108), (100, 108))"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape, y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42327674488422851"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean((y_hat - y_true)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.54509898583379723, -0.39908957525453698, 0.9779543984237089, 0.0)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.max(), y_hat.min(), y_true.max(), y_true.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Loss of the generated traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Persistent chain for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def split_vis_rowdata(crbm: CRBM, vis: np.ndarray):\n",
    "    n_his = vis.shape[0]\n",
    "    cond = vis[0:(n_his-1), :].T\n",
    "    x = vis[[n_his-1],:].T\n",
    "    \n",
    "    assert  crbm.n_vis == x.shape[0] and crbm.n_vis == cond.shape[0], \\\n",
    "            \"crbm.n_vis = {}, is different from x.shape[0] = {} or cond.shape[0] = {}\".format(crbm.n_vis,\n",
    "                                                                                                  x.shape[0],\n",
    "                                                                                                  cond.shape[0])\n",
    "    return x, cond\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_vis_coldata(crbm: CRBM, vis: np.ndarray):\n",
    "    n_his = vis.shape[0]\n",
    "    cond = vis[:, 0:(n_his-1)]\n",
    "    x = vis[[n_his-1],:]\n",
    "    \n",
    "    assert  crbm.n_vis == x.shape[0] and crbm.n_vis == cond.shape[0], \\\n",
    "            \"crbm.n_vis = {}, is different from x.shape[0] = {} or cond.shape[0] = {}\".format(crbm.n_vis,\n",
    "                                                                                                  x.shape[0],\n",
    "                                                                                                  cond.shape[0])\n",
    "    return x, cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions with persistent chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare an example that trains with several data and predict feature values\n",
    "\n",
    "```\n",
    "forecast_crbm <- forecast.crbm <- function(crbm, orig_data, orig_history = NULL, n_samples = 10, n_gibbs = 30)\n",
    "{\n",
    "\tif (is.null(orig_history))\n",
    "\t{\n",
    "\t\tl <- nrow(orig_data);\n",
    "\t\torig_history <- orig_data[l - 1:crbm$delay,, drop=FALSE];\n",
    "\t\torig_history <- array(t(orig_history), c(1, crbm$n_visible * crbm$delay));\n",
    "\t\torig_data <- orig_data[l,, drop = FALSE];\n",
    "\t\tn_seq <- 1;\n",
    "\t} else {\n",
    "\t\tn_seq <- nrow(orig_data);\n",
    "\t}\n",
    "\t\n",
    "\tpersistent_vis_chain <<- orig_data;\n",
    "\tpersistent_history <<- orig_history;\n",
    "\n",
    "    # construct the function that implements our persistent chain.\n",
    "\tsample_fn <- function(crbm, n_gibbs)\n",
    "\t{\n",
    "\t\tvis_sample <- persistent_vis_chain;\n",
    "\t\tv_history <- persistent_history;\n",
    "\n",
    "\t\tvis_mf <- NULL;\n",
    "\t\tfor (k in 1:n_gibbs)\n",
    "\t\t{\n",
    "\t\t\thid <- sample_h_given_v_crbm(crbm, vis_sample, v_history);\n",
    "\t\t\tvis <- sample_v_given_h_crbm(crbm, hid[[\"sample\"]], v_history);\n",
    "\n",
    "\t\t\tvis_mf <- vis[[\"mean\"]];\n",
    "\t\t\tvis_sample <- vis[[\"sample\"]];\n",
    "\t\t}\n",
    "\n",
    "\t\t# add to updates the shared variable that takes care of our persistent chain\n",
    "\t\tpersistent_vis_chain <<- vis_sample;\n",
    "\t\tpersistent_history <<- cbind(vis_sample, persistent_history[,1:((crbm$delay - 1) * crbm$n_visible), drop = FALSE]);\n",
    "\n",
    "\t\tvis_mf;\n",
    "\t}\n",
    "\n",
    "\tgenerated_series <- array(0,c(n_seq, n_samples, crbm$n_visible));\n",
    "\tfor (t in 1:n_samples)\n",
    "\t{\n",
    "\t\t#if (t %% 10 == 1) print(paste(\"Generating frame \", t, \" to \", min(t+9, n_samples), sep = \"\"));\n",
    "\t\tgenerated_series[,t,] <- sample_fn(crbm, n_gibbs);\n",
    "\t}\n",
    "\tgenerated_series;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_persistent(crbm, orig_data, orig_hist, n_samples, n_gibbs=10):\n",
    "    \"\"\" \n",
    "    Given initialization(s) of visibles and matching history, generate n_samples in future.\n",
    "    \n",
    "        orig_data : n_seq by n_visibles array\n",
    "            initialization for first frame\n",
    "            \n",
    "        orig_history : n_seq by delay * n_visibles array\n",
    "            delay-step history\n",
    "            \n",
    "        n_samples : int\n",
    "            number of samples to generate forward\n",
    "            \n",
    "        n_gibbs : int\n",
    "            number of alternating Gibbs steps per iteration\n",
    "    \"\"\"\n",
    "    n_seq = orign_data.shape[0]\n",
    "    persistent_vis_chain = None\n",
    "    persistent_history   = None\n",
    "    \n",
    "    return generated_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
