{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Diary for CRBM implementation\n",
    "\n",
    "\n",
    "\n",
    "This notebook shows the parts from `crbm.py` with some details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import numexpr as ne\n",
    "import sklearn\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### read data from  `../Datasets/motion.mat`\n",
    "\n",
    "More data from human motion captures can be found here:\n",
    "\n",
    "http://people.csail.mit.edu/ehsu/work/sig05stf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat  # this is the SciPy module that loads mat-files\n",
    "data = loadmat('../Datasets/motion.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'skel', 'Motion'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = data[\"Motion\"][0][0]\n",
    "X2 = data[\"Motion\"][0][1]\n",
    "X3 = data[\"Motion\"][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1750, 108), (1040, 108), (1040, 108))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape, X2.shape, X2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several features are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(X1 - np.min(X1,0)) / (np.max(X1,0) - np.min(X1,0))* (np.min(X1,0) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1049.559326171875, 490.09881591796881, (1750, 108))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[:,3].min(), X1[:,3].max(), X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = X1.shape[1]\n",
    "for f in range(n_features):\n",
    "    max_val, min_val =  X1[:, f].max(), X1[:, f].min()\n",
    "    if (max_val - min_val) != 0:\n",
    "        X1[:, f] = ( X1[:, f]  - min_val)  / (max_val - min_val)\n",
    "    else:\n",
    "        #print(f, max_val, max_val)\n",
    "        X1[:, f] = ( X1[:, f]  - min_val) # / (max_val - min_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.min(), X1.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRBM class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 10\n",
    "b=2\n",
    "np.zeros([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CRBM:\n",
    "    def __init__(self, n_vis, n_hid, n_cond, seed=42, sigma=0.3, monitor_time=True):\n",
    "\n",
    "        self.previous_xneg = None\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        W = 0.01* np.random.normal(0, sigma, [n_hid, n_vis])   # vis to hid\n",
    "        A = 0.01*  np.random.normal(0, sigma, [n_vis, n_vis * n_cond])  # cond to vis\n",
    "        B = 0.01*  np.random.normal(0, sigma, [n_hid, n_vis * n_cond])  # cond to hid\n",
    "\n",
    "        v_bias = np.zeros([n_vis, 1]) \n",
    "        h_bias = np.zeros([n_hid, 1])\n",
    "\n",
    "        dy_v_bias = np.zeros([n_vis, 1])\n",
    "        dy_h_bias = np.zeros([n_hid, 1])\n",
    "\n",
    "        self.W = np.array(W, dtype='float32')\n",
    "        self.A = np.array(A, dtype='float32')\n",
    "        self.B = np.array(B, dtype='float32')\n",
    "        self.v_bias = v_bias\n",
    "        self.h_bias = h_bias\n",
    "        self.dy_v_bias = dy_v_bias\n",
    "        self.dy_h_bias = dy_h_bias\n",
    "        \n",
    "        self.n_vis = n_vis\n",
    "        self.n_hid = n_hid\n",
    "        self.n_his = n_cond\n",
    "        \n",
    "        self.num_epochs_trained = 0\n",
    "        self.lr = 0\n",
    "        self.monitor_time = monitor_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crbm = CRBM(n_vis=108, n_hid=256, n_cond=20, seed=123, sigma = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256, 108), (108, 2160), (256, 2160))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crbm.W.shape, crbm.A.shape, crbm.B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sig(v):\n",
    "    return ne.evaluate(\"1/(1 + exp(-v))\")\n",
    "\n",
    "\n",
    "def split_vis(crbm: CRBM, vis: np.ndarray):\n",
    "    n_his = vis.shape[0]\n",
    "    cond = vis[0:(n_his-1), :].T\n",
    "    x = vis[[n_his-1],:].T\n",
    "    \n",
    "    assert  crbm.n_vis == x.shape[0] and crbm.n_vis == cond.shape[0], \\\n",
    "            \"crbm.n_vis = {}, is different from x.shape[0] = {} or cond.shape[0] = {}\".format(crbm.n_vis,\n",
    "                                                                                                  x.shape[0],\n",
    "                                                                                                  cond.shape[0])\n",
    "    return x, cond\n",
    "\n",
    "\n",
    "def dynamic_biases_up(crbm: CRBM, cond: np.ndarray):\n",
    "    crbm.dy_v_bias = np.dot(crbm.A, cond) + crbm.v_bias \n",
    "    crbm.dy_h_bias = np.dot(crbm.B, cond) + crbm.h_bias\n",
    "        \n",
    "        \n",
    "def hid_means(crbm: CRBM, vis: np.ndarray):\n",
    "    p = np.dot(crbm.W, vis) + crbm.dy_h_bias\n",
    "    return sig(p)\n",
    "    \n",
    "    \n",
    "def vis_means(crbm: CRBM, hid: np.ndarray):   \n",
    "    p = np.dot(crbm.W.T, hid) + crbm.dy_v_bias\n",
    "    return sig(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, 108), 20)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X1[0:21, :]\n",
    "X.shape, crbm.n_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108, 1), (108, 20))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis, cond = split_vis(crbm, X)\n",
    "vis.shape, cond.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute gradients\n",
    "\n",
    "```\n",
    "function gibbs(rbm::AbstractRBM, vis::Mat; n_times=1)\n",
    "    v_pos = vis\n",
    "    h_pos = sample_hiddens(rbm, v_pos)\n",
    "    v_neg = sample_visibles(rbm, h_pos)\n",
    "    h_neg = sample_hiddens(rbm, v_neg)\n",
    "    for i=1:n_times-1\n",
    "        v_neg = sample_visibles(rbm, h_neg)\n",
    "        h_neg = sample_hiddens(rbm, v_neg)\n",
    "    end\n",
    "    return v_pos, h_pos, v_neg, h_neg\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample_hiddens(crbm: CRBM, v: np.ndarray, cond: np.ndarray):\n",
    "    h_mean = sig( np.dot(crbm.W, v) +  np.dot(crbm.B, cond) + crbm.h_bias)\n",
    "    h_sample = h_mean > np.random.random(h_mean.shape).astype(np.float32)\n",
    "    return h_sample, h_mean\n",
    "\n",
    "\n",
    "def sample_visibles(crbm: CRBM, h: np.ndarray, cond: np.ndarray):\n",
    "    \"\"\"\n",
    "    Notice we don't sample or put the sigmoid here since visible units are Gaussian\n",
    "    \"\"\"\n",
    "    v_mean = np.dot(crbm.W.T, h) + np.dot(crbm.A, cond) + crbm.v_bias  \n",
    "    return v_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CDK(crbm, vis,cond, K=1):\n",
    "    v_pos_mean = vis\n",
    "    h_pos_sample, h_pos_mean    = sample_hiddens(crbm,  v_pos_mean, cond)\n",
    "    v_neg_mean                  = sample_visibles(crbm, h_pos_mean, cond)\n",
    "    h_neg_sample, h_neg_mean    = sample_hiddens(crbm,  v_neg_mean, cond)\n",
    "\n",
    "    for i in range(K-1):\n",
    "        v_neg_mean           = sample_visibles(crbm, h_neg_mean, cond)\n",
    "        h_neg, h_neg_mean    = sample_hiddens(crbm,  v_neg_mean, cond)\n",
    "    \n",
    "    return v_pos_mean, h_pos_mean , v_neg_mean, h_neg_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update history in matrix form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 1],\n",
       "       [3, 2, 1],\n",
       "       [3, 2, 1]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[3,3,3],[2,2,2],[1,1,1]]).T\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,0:-1] = a[:,1:]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 7],\n",
       "       [2, 1, 7],\n",
       "       [2, 1, 7]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,-1] = [7,7,7]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_history_as_mat(current_hist, vec_to_hist):\n",
    "    current_hist[:,0:-1] = current_hist[:,1:]\n",
    "    current_hist[:,-1] = vec_to_hist\n",
    "    return current_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 7],\n",
       "       [2, 1, 7],\n",
       "       [2, 1, 7]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[3,3,3],[2,2,2],[1,1,1]]).T\n",
    "v = np.array([7,7,7])\n",
    "update_history_as_mat(a, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update history in column vector form\n",
    "\n",
    "Notice that first column in the matrix corresponds to oldest feature vector (first to be popped out):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 1],\n",
       "       [3, 2, 1],\n",
       "       [3, 2, 1]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[3,3,3],[2,2,2],[1,1,1]]).T\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what we want to do\n",
    "a = np.array([a.flatten('F')]).T\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7],\n",
       "       [7],\n",
       "       [7]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_new = np.array([[7,7,7]]).T\n",
    "n_feat = v_new.shape[0]\n",
    "v_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0:-n_feat] = a[n_feat:] \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-3:] = v_new\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_history_as_vec(current_hist_vec, v_new):\n",
    "    n_feat = v_new.shape[0]\n",
    "    current_hist_vec[0:-n_feat] = current_hist_vec[n_feat:] \n",
    "    current_hist_vec[-n_feat:] = v_new\n",
    "    return current_hist_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[3,3,3],[2,2,2],[1,1,1]]).T\n",
    "a = np.array([a.flatten('F')]).T\n",
    "\n",
    "update_history_as_vec(a, v_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def history_mat_to_vec(cond):\n",
    "    return np.array([cond.flatten('F')]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient(crbm, X):\n",
    "    \"\"\"\n",
    "    Computes an approximated gradient of the likelihod (for a given minibatch X) with\n",
    "    respect to the parameters. \n",
    "    \"\"\"\n",
    "    vis, cond = split_vis(crbm, X)\n",
    "    cond = history_mat_to_vec(cond)\n",
    "        \n",
    "    v_pos, h_pos, v_neg, h_neg = CDK(crbm, vis, cond)\n",
    "    n_obs = vis.shape[1]\n",
    "    \n",
    "    # for a sigle observation:  dW = h * v^T - h_hat * v_hat^T\n",
    "    dW = ( np.dot(h_pos, v_pos.T) - np.dot(h_neg, v_neg.T) ) * (1./n_obs)\n",
    "    dA = ( np.dot(v_pos, cond.T)  - np.dot(v_neg, cond.T)  ) * (1./n_obs)\n",
    "    dB = ( np.dot(h_pos, cond.T)  - np.dot(h_neg, cond.T)  ) * (1./n_obs) \n",
    "    \n",
    "    dv_bias = np.mean(v_pos - v_neg, axis=1, keepdims=True)\n",
    "    dh_bias = np.mean(h_pos - h_neg, axis=1, keepdims=True)\n",
    "    #print(\"n_obs:\", n_obs)\n",
    "    \n",
    "    rec_error = np.linalg.norm(v_pos - v_neg)\n",
    "    #print( np.sqrt(np.sum((v_pos - v_neg)**2)))\n",
    "    \n",
    "    return dW, dA, dB, dv_bias, dh_bias, rec_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X1[0:21,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, 108), 20)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, crbm.n_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the history is converted to a \"long column vector\" concatenating\n",
    "# all the rows of the n_his vectors into a single vector of `n_vis * n_his` elements.\n",
    "# This is done by `cond = np.array([cond.flatten()]).T`\n",
    "\n",
    "dW, dA, dB, dv_bias, dh_bias, rec_error = compute_gradient(crbm, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, 108), 3.803455372598179)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, rec_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights_sgd(crbm, grads, learning_rate):\n",
    "    \n",
    "    dW, dA, dB, dv_bias, dh_bias = grads #rec_error = compute_gradient(crbm, X)\n",
    "    crbm.W += dW * learning_rate\n",
    "    crbm.A += dA * learning_rate\n",
    "    crbm.B += dB * learning_rate\n",
    "    \n",
    "    crbm.v_bias += dv_bias * learning_rate\n",
    "    crbm.h_bias += dh_bias * learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error: 3.8034553726\n",
      "reconstruction error: 2.42335018933\n",
      "reconstruction error: 1.54233514485\n",
      "reconstruction error: 0.980735734727\n",
      "reconstruction error: 0.62322001953\n",
      "reconstruction error: 0.395854383213\n",
      "reconstruction error: 0.251361849723\n",
      "reconstruction error: 0.15957990695\n",
      "reconstruction error: 0.101298290013\n",
      "reconstruction error: 0.0642970197574\n"
     ]
    }
   ],
   "source": [
    "crbm = CRBM(n_vis=108, n_hid=256, n_cond=20, seed=123, sigma = 0.3)\n",
    "learning_rate = 0.001\n",
    "\n",
    "for i in range(10):\n",
    "    dW, dA, dB, dv_bias, dh_bias, err = compute_gradient(crbm, X)\n",
    "    grads  = (dW, dA, dB, dv_bias, dh_bias)\n",
    "    update_weights_sgd(crbm, grads,  learning_rate)\n",
    "    print(\"reconstruction error:\", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights_sgd_momentum(crbm, grads, learning_rate, ctx, momentum=0.9):\n",
    "    \n",
    "    dW, dA, dB, dv_bias, dh_bias = grads \n",
    "    \n",
    "    ctx[\"W_vel\"]        = ctx[\"W_vel\"]      * momentum    +  dW      * learning_rate\n",
    "    ctx[\"A_vel\"]        = ctx[\"A_vel\"]      * momentum    +  dA      * learning_rate\n",
    "    ctx[\"B_vel\"]        = ctx[\"B_vel\"]      * momentum    +  dB      * learning_rate\n",
    "    ctx[\"v_bias_vel\"]   = ctx[\"v_bias_vel\"] * momentum    +  dv_bias * learning_rate\n",
    "    ctx[\"h_bias_vel\"]   = ctx[\"h_bias_vel\"] * momentum    +  dh_bias * learning_rate\n",
    "    \n",
    "    crbm.W += ctx[\"W_vel\"]\n",
    "    crbm.A += ctx[\"A_vel\"] \n",
    "    crbm.B += ctx[\"B_vel\"] \n",
    "    \n",
    "    crbm.v_bias += ctx[\"v_bias_vel\"]\n",
    "    crbm.h_bias += ctx[\"h_bias_vel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error: 3.8034553726\n",
      "reconstruction error: 2.42335018933\n",
      "reconstruction error: 1.26588140914\n",
      "reconstruction error: 0.57295464037\n",
      "reconstruction error: 0.225242692508\n",
      "reconstruction error: 0.0734360975395\n",
      "reconstruction error: 0.0162494759865\n",
      "reconstruction error: 0.00114362695359\n",
      "reconstruction error: 0.0041909802996\n",
      "reconstruction error: 0.0032719421663\n"
     ]
    }
   ],
   "source": [
    "crbm = CRBM(n_vis=108, n_hid=256, n_cond=20, seed=123, sigma = 0.3)\n",
    "learning_rate = 0.001\n",
    "\n",
    "ctx = { \"W_vel\" : np.zeros(crbm.W.shape), \n",
    "        \"A_vel\" : np.zeros(crbm.A.shape),\n",
    "        \"B_vel\" : np.zeros(crbm.B.shape), \n",
    "        \"v_bias_vel\" : np.zeros(crbm.v_bias.shape), \n",
    "        \"h_bias_vel\" : np.zeros(crbm.h_bias.shape)}\n",
    "\n",
    "for i in range(10):\n",
    "    dW, dA, dB, dv_bias, dh_bias, err = compute_gradient(crbm, X)\n",
    "    grads  = (dW, dA, dB, dv_bias, dh_bias)\n",
    "    update_weights_sgd_momentum(crbm, grads, learning_rate, ctx, momentum=0.2)\n",
    "    print(\"reconstruction error:\", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get slice of data\n",
    "\n",
    "Given a timeseries where column `k` corresponds to a feature vector for the measurements of the timeseries at time `k`, we would like to take a slice of `n_his` values to feed the CRBM with a visible vector and a history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 108)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_slice_at_position_k(X, k, n_his):\n",
    "    \"\"\"\n",
    "    Returns a slice of shape  `(n_his + 1)` with the last column beeing the visible\n",
    "    vector at the current time step `k`.\n",
    "    \"\"\"\n",
    "    assert k > n_his, \"Position k = {} is lower than n_his = {}\".format(k, n_his)\n",
    "    assert k <= X.shape[1], \"Position k = {} is bigger than number of timesteps of X.shape[1] = {}\".format(k, X.shape[0])\n",
    "    return X[:, (k-(n_his+1)):k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr shape:  (108, 1750) \n",
      "slice shape: (108, 21)\n"
     ]
    }
   ],
   "source": [
    "X_tr = X1.T\n",
    "print(\"X_tr shape: \", X_tr.shape, \"\\nslice shape:\", get_slice_at_position_k(X_tr, 520, crbm.n_his).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train some  epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108, 1750), 1750, 108, 256, 20)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr = X1.T\n",
    "X_tr.shape, X_tr.shape[1],  crbm.n_vis, crbm.n_hid, crbm.n_his"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec error:  0.306481827782\n",
      "rec error:  0.281376627421\n",
      "rec error:  0.264481296278\n",
      "rec error:  0.250660169604\n",
      "rec error:  0.241005474872\n",
      "rec error:  0.235118032331\n",
      "rec error:  0.22848063363\n",
      "rec error:  0.22299100859\n",
      "rec error:  0.218595265913\n",
      "rec error:  0.21536331107\n",
      "CPU times: user 5min 39s, sys: 11.8 s, total: 5min 51s\n",
      "Wall time: 2min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crbm = CRBM(n_vis=108, n_hid=256, n_cond=10, seed=123, sigma = 0.3)\n",
    "n_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "ctx = { \"W_vel\" : np.zeros(crbm.W.shape), \n",
    "        \"A_vel\" : np.zeros(crbm.A.shape),\n",
    "        \"B_vel\" : np.zeros(crbm.B.shape), \n",
    "        \"v_bias_vel\" : np.zeros(crbm.v_bias.shape), \n",
    "        \"h_bias_vel\" : np.zeros(crbm.h_bias.shape)}\n",
    "\n",
    "for n in range(n_epochs):\n",
    "    err_epoch = 0\n",
    "    iters = 0\n",
    "    for k in range(crbm.n_his + 1, X_tr.shape[1] ):\n",
    "\n",
    "        X_curr = get_slice_at_position_k(X_tr, k, crbm.n_his)\n",
    "        dW, dA, dB, dv_bias, dh_bias, rec_error = compute_gradient(crbm, X_curr.T)\n",
    "        grads = (dW, dA, dB, dv_bias, dh_bias)\n",
    "        update_weights_sgd_momentum(crbm, grads, learning_rate, ctx, momentum=0.2)\n",
    "        iters +=1\n",
    "        err_epoch += rec_error\n",
    "        \n",
    "    print(\"rec error: \", err_epoch/iters)#, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec error:  0.177934999331\n",
      "rec error:  0.141553903892\n",
      "rec error:  0.131299616937\n",
      "rec error:  0.125575453928\n",
      "rec error:  0.122641461558\n",
      "rec error:  0.120646690804\n",
      "rec error:  0.118690350513\n",
      "rec error:  0.117463262574\n",
      "rec error:  0.117166993136\n",
      "rec error:  0.116768897521\n",
      "CPU times: user 4min 38s, sys: 10.5 s, total: 4min 48s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crbm = CRBM(n_vis=108, n_hid=256, n_cond=10, seed=123, sigma = 0.3)\n",
    "n_epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "ctx = { \"W_vel\" : np.zeros(crbm.W.shape), \n",
    "        \"A_vel\" : np.zeros(crbm.A.shape),\n",
    "        \"B_vel\" : np.zeros(crbm.B.shape), \n",
    "        \"v_bias_vel\" : np.zeros(crbm.v_bias.shape), \n",
    "        \"h_bias_vel\" : np.zeros(crbm.h_bias.shape)}\n",
    "\n",
    "for n in range(n_epochs):\n",
    "    err_epoch = 0\n",
    "    iters = 0\n",
    "    for k in range(crbm.n_his + 1, X_tr.shape[1] ):\n",
    "\n",
    "        X_curr = get_slice_at_position_k(X_tr, k, crbm.n_his)\n",
    "        dW, dA, dB, dv_bias, dh_bias, rec_error = compute_gradient(crbm, X_curr.T)\n",
    "        grads = (dW, dA, dB, dv_bias, dh_bias)\n",
    "        update_weights_sgd_momentum(crbm, grads, learning_rate, ctx, momentum=0.2)\n",
    "        iters +=1\n",
    "        err_epoch += rec_error\n",
    "        \n",
    "    print(\"rec error: \", err_epoch/iters)#, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec error:  14.7289213466\n",
      "rec error:  2.18940638416\n",
      "rec error:  2.07811242966\n",
      "rec error:  1.98669792069\n",
      "rec error:  1.90378431112\n",
      "rec error:  1.82770912812\n",
      "rec error:  1.764656634\n",
      "rec error:  1.71062368537\n",
      "rec error:  1.65315915927\n",
      "rec error:  1.60457744667\n",
      "CPU times: user 3min 11s, sys: 7.63 s, total: 3min 19s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crbm = CRBM(n_vis=108, n_hid=256, n_cond=10, seed=123, sigma = 0.3)\n",
    "n_epochs = 10\n",
    "learning_rate = 0.01 # we have increased the  learning rate\n",
    "\n",
    "for n in range(n_epochs):\n",
    "    err_epoch = 0\n",
    "    iters = 0\n",
    "    for k in range(crbm.n_his + 1, X_tr.shape[1] ):\n",
    "\n",
    "        X_curr = get_slice_at_position_k(X_tr, k, crbm.n_his)\n",
    "        dW, dA, dB, dv_bias, dh_bias, rec_error = compute_gradient(crbm, X_curr.T)\n",
    "        grads = (dW, dA, dB, dv_bias, dh_bias)\n",
    "        update_weights_sgd(crbm, grads,  learning_rate)\n",
    "        iters +=1\n",
    "        err_epoch += rec_error\n",
    "        \n",
    "    print(\"rec error: \", err_epoch/iters)#, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108, 1750), (108,))"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a timeseries where rows are features and columns timesteps (1750 timesteps and 108 features)\n",
    "X_tr.shape, X_tr[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(crbm, vis, cond_as_vec, n_gibbs=10):\n",
    "    \"\"\" \n",
    "    Given initialization(s) of visibles and matching history, generate a sample in the future.\n",
    "    \n",
    "        vis:  n_vis * 1 array\n",
    "            \n",
    "        cond_as_vec: n_hist * n_vis array\n",
    "            \n",
    "        n_gibbs : int\n",
    "            number of alternating Gibbs steps per iteration\n",
    "    \"\"\"\n",
    "    \n",
    "    assert cond_as_vec.shape[1] ==1, \"cond_as_vec has to be a column vector\"\n",
    "    \n",
    "    n_seq = vis.shape[0]\n",
    "    #import pdb; pdb.set_trace()\n",
    "    v_pos, h_pos, v_neg, h_neg = CDK(crbm, vis, cond_as_vec, n_gibbs)\n",
    "    \n",
    "    return v_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_n_samples(crbm, vis, cond_as_vec, n_samples, n_gibbs=10):\n",
    "    \"\"\" \n",
    "    Given initialization(s) of visibles and matching history, generate a n_samples in the future.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert cond_as_vec.shape[1] ==1, \"cond_as_vec has to be a column vector\"\n",
    "    \n",
    "    samples = []\n",
    "    for i in range(n_samples):\n",
    "        v_new = generate(crbm, vis, cond_as_vec, n_gibbs)\n",
    "        \n",
    "        # This should not be here\n",
    "        v_new = v_new/np.linalg.norm(v_new)      \n",
    "        update_history_as_vec(cond_as_vec, v_new)\n",
    "        \n",
    "        samples.append(v_new)\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v    = X_tr[:, [crbm.n_his+1]]\n",
    "hist = X_tr[:, 0:crbm.n_his+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, (108, 1), (108, 11), (21, 108))"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crbm.n_vis,  v.shape, hist.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 10)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis, cond = split_vis(crbm, hist.T)\n",
    "cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cond_as_vec =  history_mat_to_vec(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.94352132901966146, 0.0)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_as_vec.max(), cond_as_vec.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108, 1), (1080, 1), 108)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape, cond_as_vec.shape, crbm.n_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 1)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_as_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108, 1080), (256, 1080), (256, 108))"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crbm.A.shape, crbm.B.shape, crbm.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = generate_n_samples(crbm, v, cond_as_vec, n_samples = 100, n_gibbs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.28260305981799355"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_as_vec.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 108)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples), len(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.315945265203 -0.0131379444896\n",
      "0.314247687258 -0.016026380618\n",
      "0.326866965915 -0.0191752262314\n",
      "0.343980369273 -0.0219303673418\n",
      "0.368368530509 -0.0277843109218\n",
      "0.0294414211905 -0.277440092798\n"
     ]
    }
   ],
   "source": [
    "print(samples[0].max(), samples[0].min())\n",
    "print(samples[1].max(), samples[1].min())\n",
    "print(samples[2].max(), samples[2].min())\n",
    "print(samples[3].max(), samples[3].min())\n",
    "print(samples[4].max(), samples[4].min())\n",
    "print(samples[-1].max(), samples[-1].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X = X1[0:21,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = X1[21:121,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.array(samples).reshape(100,108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 108), (100, 108))"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape, y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42327674488422851"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean((y_hat - y_true)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.54509898583379723, -0.39908957525453698, 0.9779543984237089, 0.0)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.max(), y_hat.min(), y_true.max(), y_true.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Loss of the generated traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Persistent chain for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def split_vis_rowdata(crbm: CRBM, vis: np.ndarray):\n",
    "    n_his = vis.shape[0]\n",
    "    cond = vis[0:(n_his-1), :].T\n",
    "    x = vis[[n_his-1],:].T\n",
    "    \n",
    "    assert  crbm.n_vis == x.shape[0] and crbm.n_vis == cond.shape[0], \\\n",
    "            \"crbm.n_vis = {}, is different from x.shape[0] = {} or cond.shape[0] = {}\".format(crbm.n_vis,\n",
    "                                                                                                  x.shape[0],\n",
    "                                                                                                  cond.shape[0])\n",
    "    return x, cond\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_vis_coldata(crbm: CRBM, vis: np.ndarray):\n",
    "    n_his = vis.shape[0]\n",
    "    cond = vis[:, 0:(n_his-1)]\n",
    "    x = vis[[n_his-1],:]\n",
    "    \n",
    "    assert  crbm.n_vis == x.shape[0] and crbm.n_vis == cond.shape[0], \\\n",
    "            \"crbm.n_vis = {}, is different from x.shape[0] = {} or cond.shape[0] = {}\".format(crbm.n_vis,\n",
    "                                                                                                  x.shape[0],\n",
    "                                                                                                  cond.shape[0])\n",
    "    return x, cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions with persistent chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare an example that trains with several data and predict feature values\n",
    "\n",
    "```\n",
    "forecast_crbm <- forecast.crbm <- function(crbm, orig_data, orig_history = NULL, n_samples = 10, n_gibbs = 30)\n",
    "{\n",
    "\tif (is.null(orig_history))\n",
    "\t{\n",
    "\t\tl <- nrow(orig_data);\n",
    "\t\torig_history <- orig_data[l - 1:crbm$delay,, drop=FALSE];\n",
    "\t\torig_history <- array(t(orig_history), c(1, crbm$n_visible * crbm$delay));\n",
    "\t\torig_data <- orig_data[l,, drop = FALSE];\n",
    "\t\tn_seq <- 1;\n",
    "\t} else {\n",
    "\t\tn_seq <- nrow(orig_data);\n",
    "\t}\n",
    "\t\n",
    "\tpersistent_vis_chain <<- orig_data;\n",
    "\tpersistent_history <<- orig_history;\n",
    "\n",
    "    # construct the function that implements our persistent chain.\n",
    "\tsample_fn <- function(crbm, n_gibbs)\n",
    "\t{\n",
    "\t\tvis_sample <- persistent_vis_chain;\n",
    "\t\tv_history <- persistent_history;\n",
    "\n",
    "\t\tvis_mf <- NULL;\n",
    "\t\tfor (k in 1:n_gibbs)\n",
    "\t\t{\n",
    "\t\t\thid <- sample_h_given_v_crbm(crbm, vis_sample, v_history);\n",
    "\t\t\tvis <- sample_v_given_h_crbm(crbm, hid[[\"sample\"]], v_history);\n",
    "\n",
    "\t\t\tvis_mf <- vis[[\"mean\"]];\n",
    "\t\t\tvis_sample <- vis[[\"sample\"]];\n",
    "\t\t}\n",
    "\n",
    "\t\t# add to updates the shared variable that takes care of our persistent chain\n",
    "\t\tpersistent_vis_chain <<- vis_sample;\n",
    "\t\tpersistent_history <<- cbind(vis_sample, persistent_history[,1:((crbm$delay - 1) * crbm$n_visible), drop = FALSE]);\n",
    "\n",
    "\t\tvis_mf;\n",
    "\t}\n",
    "\n",
    "\tgenerated_series <- array(0,c(n_seq, n_samples, crbm$n_visible));\n",
    "\tfor (t in 1:n_samples)\n",
    "\t{\n",
    "\t\t#if (t %% 10 == 1) print(paste(\"Generating frame \", t, \" to \", min(t+9, n_samples), sep = \"\"));\n",
    "\t\tgenerated_series[,t,] <- sample_fn(crbm, n_gibbs);\n",
    "\t}\n",
    "\tgenerated_series;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_persistent(crbm, orig_data, orig_hist, n_samples, n_gibbs=10):\n",
    "    \"\"\" \n",
    "    Given initialization(s) of visibles and matching history, generate n_samples in future.\n",
    "    \n",
    "        orig_data : n_seq by n_visibles array\n",
    "            initialization for first frame\n",
    "            \n",
    "        orig_history : n_seq by delay * n_visibles array\n",
    "            delay-step history\n",
    "            \n",
    "        n_samples : int\n",
    "            number of samples to generate forward\n",
    "            \n",
    "        n_gibbs : int\n",
    "            number of alternating Gibbs steps per iteration\n",
    "    \"\"\"\n",
    "    n_seq = orign_data.shape[0]\n",
    "    persistent_vis_chain = None\n",
    "    persistent_history   = None\n",
    "    \n",
    "    return generated_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
