{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Diary for CRBM implementation\n",
    "\n",
    "\n",
    "\n",
    "This notebook shows the parts from `crbm.py` with some details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import numexpr as ne\n",
    "import sklearn\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### read data from  `../Datasets/motion.mat`\n",
    "\n",
    "More data from human motion captures can be found here:\n",
    "\n",
    "http://people.csail.mit.edu/ehsu/work/sig05stf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat  # this is the SciPy module that loads mat-files\n",
    "data = loadmat('../Datasets/motion.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'skel', 'Motion'])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = data[\"Motion\"][0][0]\n",
    "X2 = data[\"Motion\"][0][1]\n",
    "X3 = data[\"Motion\"][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1750, 108), (1040, 108), (1040, 108))"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape, X2.shape, X2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several features are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(X1 - np.min(X1,0)) / (np.max(X1,0) - np.min(X1,0))* (np.min(X1,0) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1049.559326171875, 490.09881591796881, (1750, 108))"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[:,3].min(), X1[:,3].max(), X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = X1.shape[1]\n",
    "for f in range(n_features):\n",
    "    max_val, min_val =  X1[:, f].max(), X1[:, f].min()\n",
    "    if (max_val - min_val) != 0:\n",
    "        X1[:, f] = ( X1[:, f]  - min_val)  / (max_val - min_val)\n",
    "    else:\n",
    "        #print(f, max_val, max_val)\n",
    "        X1[:, f] = ( X1[:, f]  - min_val) # / (max_val - min_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.min(), X1.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRBM class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 10\n",
    "b=2\n",
    "np.zeros([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CRBM:\n",
    "    def __init__(self, n_vis, n_hid, n_cond, seed=42, sigma=0.3, monitor_time=True):\n",
    "\n",
    "        self.previous_xneg = None\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        W = np.random.normal(0, sigma, [n_hid, n_vis])   # vis to hid\n",
    "        A = np.random.normal(0, sigma, [n_vis, n_vis * n_cond])  # cond to vis\n",
    "        B = np.random.normal(0, sigma, [n_hid, n_vis * n_cond])  # cond to hid\n",
    "\n",
    "        v_bias = np.zeros([n_vis, 1]) \n",
    "        h_bias = np.zeros([n_hid, 1])\n",
    "\n",
    "        dy_v_bias = np.zeros([n_vis, 1])\n",
    "        dy_h_bias = np.zeros([n_hid, 1])\n",
    "\n",
    "        self.W = np.array(W, dtype='float32')\n",
    "        self.A = np.array(A, dtype='float32')\n",
    "        self.B = np.array(B, dtype='float32')\n",
    "        self.v_bias = v_bias\n",
    "        self.h_bias = h_bias\n",
    "        self.dy_v_bias = dy_v_bias\n",
    "        self.dy_h_bias = dy_h_bias\n",
    "        \n",
    "        self.n_vis = n_vis\n",
    "        self.n_hid = n_hid\n",
    "        self.n_his = n_cond\n",
    "        \n",
    "        self.num_epochs_trained = 0\n",
    "        self.lr = 0\n",
    "        self.monitor_time = monitor_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crbm = CRBM(n_vis=108, n_hid=256, n_cond=20, seed=123, sigma = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256, 108), (108, 2160), (256, 2160))"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crbm.W.shape, crbm.A.shape, crbm.B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sig(v):\n",
    "    return ne.evaluate(\"1/(1 + exp(-v))\")\n",
    "\n",
    "\n",
    "def split_vis(crbm: CRBM, vis: np.ndarray):\n",
    "    n_his = vis.shape[0]\n",
    "    cond = vis[0:(n_his-1), :].T\n",
    "    x = vis[[n_his-1],:].T\n",
    "    \n",
    "    assert  crbm.n_vis == x.shape[0] and crbm.n_vis == cond.shape[0], \\\n",
    "            \"crbm.n_vis = {}, is different from x.shape[0] = {} or cond.shape[0] = {}\".format(crbm.n_vis,\n",
    "                                                                                                  x.shape[0],\n",
    "                                                                                                  cond.shape[0])\n",
    "    return x, cond\n",
    "\n",
    "\n",
    "def dynamic_biases_up(crbm: CRBM, cond: np.ndarray):\n",
    "    crbm.dy_v_bias = np.dot(crbm.A, cond) + crbm.v_bias \n",
    "    crbm.dy_h_bias = np.dot(crbm.B, cond) + crbm.h_bias\n",
    "        \n",
    "        \n",
    "def hid_means(crbm: CRBM, vis: np.ndarray):\n",
    "    p = np.dot(crbm.W, vis) + crbm.dy_h_bias\n",
    "    return sig(p)\n",
    "    \n",
    "    \n",
    "def vis_means(crbm: CRBM, hid: np.ndarray):   \n",
    "    p = np.dot(crbm.W.T, hid) + crbm.dy_v_bias\n",
    "    return sig(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, 108), 20)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X1[0:21, :]\n",
    "X.shape, crbm.n_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108, 1), (108, 20))"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis, cond = split_vis(crbm, X)\n",
    "vis.shape, cond.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute gradients\n",
    "\n",
    "```\n",
    "function gibbs(rbm::AbstractRBM, vis::Mat; n_times=1)\n",
    "    v_pos = vis\n",
    "    h_pos = sample_hiddens(rbm, v_pos)\n",
    "    v_neg = sample_visibles(rbm, h_pos)\n",
    "    h_neg = sample_hiddens(rbm, v_neg)\n",
    "    for i=1:n_times-1\n",
    "        v_neg = sample_visibles(rbm, h_neg)\n",
    "        h_neg = sample_hiddens(rbm, v_neg)\n",
    "    end\n",
    "    return v_pos, h_pos, v_neg, h_neg\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample_hiddens(crbm: CRBM, v: np.ndarray, cond: np.ndarray):\n",
    "    h_mean = sig( np.dot(crbm.W, v) +  np.dot(crbm.B, cond) + crbm.h_bias)\n",
    "    h_sample = h_mean > np.random.random(h_mean.shape).astype(np.float32)\n",
    "    return h_sample, h_mean\n",
    "\n",
    "\n",
    "def sample_visibles(crbm: CRBM, h: np.ndarray, cond: np.ndarray):\n",
    "    \"\"\"\n",
    "    Notice we don't sample or put the sigmoid here since visible units are Gaussian\n",
    "    \"\"\"\n",
    "    v_mean = np.dot(crbm.W.T, h) + np.dot(crbm.A, cond) + crbm.v_bias  \n",
    "    return v_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CDK(crbm, vis,cond, K=1):\n",
    "    v_pos = vis\n",
    "    h_pos, h_pos_p = sample_hiddens(crbm, v_pos, cond)\n",
    "    v_neg          = sample_visibles(crbm, h_pos, cond)\n",
    "    h_neg, h_neg_p = sample_hiddens(crbm, v_neg, cond)\n",
    "\n",
    "    for i in range(K-1):\n",
    "        v_neg           = sample_visibles(crbm, h_neg, cond)\n",
    "        h_neg, h_neg_p  = sample_hiddens(crbm, v_neg, cond)\n",
    "    \n",
    "    return v_pos, h_pos_p , v_neg, h_neg_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update history in matrix form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 1],\n",
       "       [3, 2, 1],\n",
       "       [3, 2, 1]])"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[3,3,3],[2,2,2],[1,1,1]]).T\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1]])"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,0:-1] = a[:,1:]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 7],\n",
       "       [2, 1, 7],\n",
       "       [2, 1, 7]])"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,-1] = [7,7,7]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_history_as_mat(current_hist, vec_to_hist):\n",
    "    current_hist[:,0:-1] = current_hist[:,1:]\n",
    "    current_hist[:,-1] = vec_to_hist\n",
    "    return current_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 7],\n",
       "       [2, 1, 7],\n",
       "       [2, 1, 7]])"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[3,3,3],[2,2,2],[1,1,1]]).T\n",
    "v = np.array([7,7,7])\n",
    "update_history_as_mat(a, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update history in column vector form\n",
    "\n",
    "Notice that first column in the matrix corresponds to oldest feature vector (first to be popped out):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 1],\n",
       "       [3, 2, 1],\n",
       "       [3, 2, 1]])"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[3,3,3],[2,2,2],[1,1,1]]).T\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what we want to do\n",
    "a = np.array([a.flatten('F')]).T\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7],\n",
       "       [7],\n",
       "       [7]])"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_new = np.array([[7,7,7]]).T\n",
    "n_feat = v_new.shape[0]\n",
    "v_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0:-n_feat] = a[n_feat:] \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7]])"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-3:] = v_new\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_history_as_vec(current_hist_vec, v_new):\n",
    "    n_feat = v_new.shape[0]\n",
    "    current_hist_vec[0:-n_feat] = current_hist_vec[n_feat:] \n",
    "    current_hist_vec[-n_feat:] = v_new\n",
    "    return current_hist_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7]])"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[3,3,3],[2,2,2],[1,1,1]]).T\n",
    "a = np.array([a.flatten('F')]).T\n",
    "\n",
    "update_history_as_vec(a, v_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def history_mat_to_vec(cond):\n",
    "    return np.array([cond.flatten('F')]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient(crbm, X):\n",
    "    \"\"\"\n",
    "    Computes an approximated gradient of the likelihod (for a given minibatch X) with\n",
    "    respect to the parameters. \n",
    "    \"\"\"\n",
    "    vis, cond = split_vis(crbm, X)\n",
    "    cond = history_mat_to_vec(cond)\n",
    "        \n",
    "    v_pos, h_pos, v_neg, h_neg = CDK(crbm, vis, cond)\n",
    "    n_obs = vis.shape[1]\n",
    "    \n",
    "    # for a sigle observation:  dW = h * v^T - h_hat * v_hat^T\n",
    "    dW = ( np.dot(h_pos, v_pos.T) - np.dot(h_neg, v_neg.T) ) * (1./n_obs)\n",
    "    dA = ( np.dot(v_pos, cond.T)  - np.dot(v_neg, cond.T)  ) * (1./n_obs)\n",
    "    dB = ( np.dot(h_pos, cond.T)  - np.dot(h_neg, cond.T)  ) * (1./n_obs) \n",
    "    \n",
    "    dv_bias = np.mean(v_pos - v_neg, axis=1, keepdims=True)\n",
    "    dh_bias = np.mean(h_pos - h_neg, axis=1, keepdims=True)\n",
    "    #print(\"n_obs:\", n_obs)\n",
    "    \n",
    "    rec_error = np.linalg.norm(v_pos - v_neg)\n",
    "    #print( np.sqrt(np.sum((v_pos - v_neg)**2)))\n",
    "    \n",
    "    return dW, dA, dB, dv_bias, dh_bias, rec_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X1[0:21,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, 108), 20)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, crbm.n_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notice that the history is converted to a \"long column vector\" concatenating\n",
    "# all the rows of the n_his vectors into a single vector of `n_vis * n_his` elements.\n",
    "# This is done by `cond = np.array([cond.flatten()]).T`\n",
    "\n",
    "dW, dA, dB, dv_bias, dh_bias, rec_error = compute_gradient(crbm, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, 108), 12.490502492519633)"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, rec_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights_sgd(crbm, grads, learning_rate):\n",
    "    \n",
    "    dW, dA, dB, dv_bias, dh_bias = grads #rec_error = compute_gradient(crbm, X)\n",
    "    crbm.W += dW * learning_rate\n",
    "    crbm.A += dA * learning_rate\n",
    "    crbm.B += dB * learning_rate\n",
    "    \n",
    "    crbm.v_bias += dv_bias * learning_rate\n",
    "    crbm.h_bias += dh_bias * learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dW, dA, dB, dv_bias, dh_bias, err = compute_gradient(crbm, X)\n",
    "grads  = (dW, dA, dB, dv_bias, dh_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_weights_sgd(crbm, grads,  0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.280228717623766"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply momentum: (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get slice of data\n",
    "\n",
    "Given a timeseries where column `k` corresponds to a feature vector for the measurements of the timeseries at time `k`, we would like to take a slice of `n_his` values to feed the CRBM with a visible vector and a history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 108)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_slice_at_position_k(X, k, n_his):\n",
    "    \"\"\"\n",
    "    Returns a slice of shape  `(n_his + 1)` with the last column beeing the visible\n",
    "    vector at the current time step `k`.\n",
    "    \"\"\"\n",
    "    assert k > n_his, \"Position k = {} is lower than n_his = {}\".format(k, n_his)\n",
    "    assert k <= X.shape[1], \"Position k = {} is bigger than number of timesteps of X.shape[1] = {}\".format(k, X.shape[0])\n",
    "    return X[:, (k-(n_his+1)):k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr shape:  (108, 1750) \n",
      "slice shape: (108, 21)\n"
     ]
    }
   ],
   "source": [
    "X_tr = X1.T\n",
    "print(\"X_tr shape: \", X_tr.shape, \"\\nslice shape:\", get_slice_at_position_k(X_tr, 520, crbm.n_his).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a single epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108, 1750), 1750, 108, 256, 20)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr = X1.T\n",
    "X_tr.shape, X_tr.shape[1],  crbm.n_vis, crbm.n_hid, crbm.n_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec error:  10.9057305238\n",
      "rec error:  11.9127497147\n",
      "rec error:  11.3451959511\n",
      "rec error:  12.5282313495\n",
      "rec error:  11.2819990777\n",
      "rec error:  11.0516846433\n",
      "rec error:  11.8774216401\n",
      "rec error:  12.236496033\n",
      "rec error:  12.0996235955\n",
      "rec error:  11.3178495407\n"
     ]
    }
   ],
   "source": [
    "for k in range(crbm.n_his+1, X_tr.shape[1]+1):\n",
    "    \n",
    "    X_curr = get_slice_at_position_k(X_tr, k, crbm.n_his)\n",
    "    dW, dA, dB, dv_bias, dh_bias, rec_error = compute_gradient(crbm, X_curr.T)\n",
    "    grads = (dW, dA, dB, dv_bias, dh_bias)\n",
    "    update_weights_sgd(crbm, grads,  0.0001)\n",
    "    \n",
    "    print(\"rec error: \", rec_error)\n",
    "    if k == 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 21)"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_curr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 1750)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a timeseries where rows are features and columns timesteps (1750 timesteps and 108 features)\n",
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108,)"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 20)"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(crbm, vis, cond_as_vec, n_gibbs=10):\n",
    "    \"\"\" \n",
    "    Given initialization(s) of visibles and matching history, generate a sample in the future.\n",
    "    \n",
    "        vis:  n_vis * 1 array\n",
    "            \n",
    "        cond_as_vec: n_hist * n_vis array\n",
    "            \n",
    "        n_gibbs : int\n",
    "            number of alternating Gibbs steps per iteration\n",
    "    \"\"\"\n",
    "    \n",
    "    assert cond_as_vec.shape[1] ==1, \"cond_as_vec has to be a column vector\"\n",
    "    \n",
    "    n_seq = orign_data.shape[0]\n",
    "    v_pos, h_pos, v_neg, h_neg = CDK(crbm, vis, cond_as_vec)\n",
    "    \n",
    "    return v_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_samples(crbm, vis, cond_as_vec, n_samples, n_gibbs=10):\n",
    "    \"\"\" \n",
    "    Given initialization(s) of visibles and matching history, generate a n_samples in the future.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert cond_as_vec.shape[1] ==1, \"cond_as_vec has to be a column vector\"\n",
    "    \n",
    "    samples = []\n",
    "    for i in range(n_samples):\n",
    "        v_new = generate(crbm, vis, cond_as_vec, n_gibbs)\n",
    "        update_history_as_vec(cond_as_vec, v_new)\n",
    "        samples.append(v_new)\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v    = X_tr[:, [crbm.n_his+1]]\n",
    "hist = X_tr[:, 0:crbm.n_his]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, (108, 1), (108, 20), (21, 108))"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crbm.n_vis,  v.shape, hist.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 20)"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis, cond = split_vis(crbm, X)\n",
    "cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cond_as_vec =  history_mat_to_vec(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = generate_n_samples(crbm, v, cond_as_vec, 100, n_gibbs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update history in vector form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def split_vis_rowdata(crbm: CRBM, vis: np.ndarray):\n",
    "    n_his = vis.shape[0]\n",
    "    cond = vis[0:(n_his-1), :].T\n",
    "    x = vis[[n_his-1],:].T\n",
    "    \n",
    "    assert  crbm.n_vis == x.shape[0] and crbm.n_vis == cond.shape[0], \\\n",
    "            \"crbm.n_vis = {}, is different from x.shape[0] = {} or cond.shape[0] = {}\".format(crbm.n_vis,\n",
    "                                                                                                  x.shape[0],\n",
    "                                                                                                  cond.shape[0])\n",
    "    return x, cond\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_vis_coldata(crbm: CRBM, vis: np.ndarray):\n",
    "    n_his = vis.shape[0]\n",
    "    cond = vis[:, 0:(n_his-1)]\n",
    "    x = vis[[n_his-1],:]\n",
    "    \n",
    "    assert  crbm.n_vis == x.shape[0] and crbm.n_vis == cond.shape[0], \\\n",
    "            \"crbm.n_vis = {}, is different from x.shape[0] = {} or cond.shape[0] = {}\".format(crbm.n_vis,\n",
    "                                                                                                  x.shape[0],\n",
    "                                                                                                  cond.shape[0])\n",
    "    return x, cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions with persistent chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare an example that trains with several data and predict feature values\n",
    "\n",
    "```\n",
    "forecast_crbm <- forecast.crbm <- function(crbm, orig_data, orig_history = NULL, n_samples = 10, n_gibbs = 30)\n",
    "{\n",
    "\tif (is.null(orig_history))\n",
    "\t{\n",
    "\t\tl <- nrow(orig_data);\n",
    "\t\torig_history <- orig_data[l - 1:crbm$delay,, drop=FALSE];\n",
    "\t\torig_history <- array(t(orig_history), c(1, crbm$n_visible * crbm$delay));\n",
    "\t\torig_data <- orig_data[l,, drop = FALSE];\n",
    "\t\tn_seq <- 1;\n",
    "\t} else {\n",
    "\t\tn_seq <- nrow(orig_data);\n",
    "\t}\n",
    "\t\n",
    "\tpersistent_vis_chain <<- orig_data;\n",
    "\tpersistent_history <<- orig_history;\n",
    "\n",
    "    # construct the function that implements our persistent chain.\n",
    "\tsample_fn <- function(crbm, n_gibbs)\n",
    "\t{\n",
    "\t\tvis_sample <- persistent_vis_chain;\n",
    "\t\tv_history <- persistent_history;\n",
    "\n",
    "\t\tvis_mf <- NULL;\n",
    "\t\tfor (k in 1:n_gibbs)\n",
    "\t\t{\n",
    "\t\t\thid <- sample_h_given_v_crbm(crbm, vis_sample, v_history);\n",
    "\t\t\tvis <- sample_v_given_h_crbm(crbm, hid[[\"sample\"]], v_history);\n",
    "\n",
    "\t\t\tvis_mf <- vis[[\"mean\"]];\n",
    "\t\t\tvis_sample <- vis[[\"sample\"]];\n",
    "\t\t}\n",
    "\n",
    "\t\t# add to updates the shared variable that takes care of our persistent chain\n",
    "\t\tpersistent_vis_chain <<- vis_sample;\n",
    "\t\tpersistent_history <<- cbind(vis_sample, persistent_history[,1:((crbm$delay - 1) * crbm$n_visible), drop = FALSE]);\n",
    "\n",
    "\t\tvis_mf;\n",
    "\t}\n",
    "\n",
    "\tgenerated_series <- array(0,c(n_seq, n_samples, crbm$n_visible));\n",
    "\tfor (t in 1:n_samples)\n",
    "\t{\n",
    "\t\t#if (t %% 10 == 1) print(paste(\"Generating frame \", t, \" to \", min(t+9, n_samples), sep = \"\"));\n",
    "\t\tgenerated_series[,t,] <- sample_fn(crbm, n_gibbs);\n",
    "\t}\n",
    "\tgenerated_series;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_persistent(crbm, orig_data, orig_hist, n_samples, n_gibbs=10):\n",
    "    \"\"\" \n",
    "    Given initialization(s) of visibles and matching history, generate n_samples in future.\n",
    "    \n",
    "        orig_data : n_seq by n_visibles array\n",
    "            initialization for first frame\n",
    "            \n",
    "        orig_history : n_seq by delay * n_visibles array\n",
    "            delay-step history\n",
    "            \n",
    "        n_samples : int\n",
    "            number of samples to generate forward\n",
    "            \n",
    "        n_gibbs : int\n",
    "            number of alternating Gibbs steps per iteration\n",
    "    \"\"\"\n",
    "    n_seq = orign_data.shape[0]\n",
    "    persistent_vis_chain = None\n",
    "    persistent_history   = None\n",
    "    \n",
    "    return generated_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
